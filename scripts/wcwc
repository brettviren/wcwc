#!/usr/bin/env python
'''
Utility to create, manage and use elements of a Wire-Cell Workstation Cluster.


'''


import os
import sys
import json
import yaml
from datetime import datetime
import click
import shutil
import sqlite3
from socket import gethostname
from getpass import getuser
import graphlib
import functools
from pathlib import Path
from collections import namedtuple

import logging
log = logging.getLogger("wcwc")
debug = log.debug
info = log.info
warn = log.warn
error = log.error


# Code may use parts of subprocess 
from subprocess import STDOUT, PIPE, CalledProcessError


# The name of the config file that will be read/written under <prefix>/
wcwc_config_filename = "wcwc.yaml"

# Default config object which may be overridden by a config file.
#
# The config largely consists of a description of a list of WCWC "stacks".
# 
# A WCWC "stack" consists of:
# - A Spack "package repo" taken from a git repo at a particular tag/branch.
# - The set of packages installed from the repo.
# - A Spack "scope".
# - A set of Spack Environments.
#
# A stack may depend on other stacks.  When a stack and dependency stack do not
# share the same install_tree then the dependency is considered an "upstream"
# Spack installation and will be "chained".  Otherwise, the dependency is
# implicit.  A WCWC stack name is also a Spack namespace and thus separation of
# stack packages can be achived using '{namespace}' in the projection.  Note,
# when upstream chaining is used, all packages are installed into the stack's
# install_tree even if they are provided by dependency repos.
# 
# Note, that the use of the Spack "builtin" repo is not implicit in wcwc
# commands.  This allows a setup that elides the builtin repo entirely or one
# that allows the builtin repo to be updated independently from the Spack
# source.  That said, default configuration includes a "base" stack that points
# to the Spack "builtin" repo.  In addition, as the user will inevitably issue
# bare "spack" commands and not set the configuration scope to a stack scope,
# the various configurations relevant to the builtin repo are set on the Spack
# instance.
#
# The configuration values may use WCWC and Spack variables.
# WCWC variables include {prefix} and {stack} and all others are Spack's.
default_config_yaml = '''
defaults:
  install_tree: "{prefix}/opt"
  projection: "{namespace}/{architecture}/{compiler.name}-{compiler.version}/{name}-{version}-{hash}"
  granularity: generic
  repo_path: "{prefix}/stacks/{stack}/repo"
  scope_path: "{prefix}/stacks/{stack}/scope"
  environments_path: "{prefix}/stacks/{stack}/environments"

stacks:
  spack:
    url: "https://github.com/spack/spack.git"
    tag: "v0.22.1"
    source_path: "{prefix}/spack"
    scope_path: "{source_path}/etc/spack"
    repo_path: "{source_path}/var/spack/repos/builtin"

  base:
    repo_path: "{prefix}/spack/var/spack/repos/builtin"
    depends:
    - spack

  wirecell:
    url: "https://github.com/WireCell/wire-cell-spack.git"
    tag: "0.28.0.2"
    depends:
    - base

  nusoft:
    url: "https://github.com/NuSoftHEP/nusofthep-spack-recipes.git"
    depends:
    - base

  art:
    url: "https://github.com/FNALssi/fnal_art.git"
    depends:
    - nusoft

  larsoft:
    url: "https://github.com/LArSoft/larsoft-spack-recipes.git"
    depends:
    - art
'''

# A hard-wired list of OSes supported by this version of WCWC.
# These are "spelled" as the output of "lsb_release -ds".
known_oses=("Debian GNU/Linux 12 (bookworm)",)


def run(cmd, lines=None, capture_error=True, **opts):
    '''
    Apply default policy to subprocess.run() to execute "cmd"

    If lines provides an integer, stdout is decoded to string and up to that
    many newline-delimited lines are returned instead of a CompletedProcess
    object.  The end of the string does NOT have a new line.

    If capture_error is true (default) then an error return code will lead to
    the stdout and stderr being logged prior to throwing.

    capture_output option is True by default and is passed to subprocess.  Set
    to False if you want stdout/stderr to not be captured.

    check option is False by default and passed to subprocess.  Set to True to
    make subprocess check the rc and maybe throw.  However, if capture_error is
    True, subprocess will be told to not check and instead, we check locally.
    '''
    from subprocess import run as srun
    if isinstance(cmd, str):
        opts["shell"]=True
    opts.setdefault("capture_output", True)
    opts.setdefault("check", False)
    if capture_error:
        opts["check"] = False
    debug(f'exec: {cmd=} {opts=}')
    rc = srun(cmd, **opts)  # throws
    if lines is None and capture_error and rc.returncode:
        error(f'command failed: {cmd}')
        out = rc.stdout.decode() if rc.stdout else ""
        error(f'output:\n{out}')
        err = rc.stderr.decode() if rc.stderr else ""
        error(f'error:\n{err}')
        rc.check_returncode()   # raise the exception

    if lines is None:
        return rc
    return '\n'.join(rc.stdout.decode().strip().split("\n")[:lines])


def which(exe, def_args=None, **def_opts):
    '''
    Find executable file "exe" and return a function that may be called like:

        func(args=None, **opts)

    Any args are appended to def_args.  If either args or def_args are string,
    the resulting command is string and executed by the shell.  If both args and
    def_args are list, the command is a list and may be directly executed unless
    shell=True option is passed.

    Any opts are merged into def_opts.

    When function func() is later called, the exe is executed with the accrued
    args and opts.  The opts are passed to run().
    '''
    path = shutil.which(str(exe))
    if path is None:
        raise FileNotFoundError(f'no such executable "{exe}"')
    if not os.access(path, os.X_OK):
        raise click.UsageError(f'not executable: {path}')
    
    debug(f'which: {exe=} {def_args=} {def_opts=}')

    def func(args=None, **opts):
        nonlocal def_args
        nonlocal def_opts

        parts = [[path], def_args, args]
        if any([isinstance(p,str) for p in parts]):
            # any a string, all a string
            line = list()
            for i,p in enumerate(parts):
                if isinstance(p, str):
                    line.append(p)
                elif p:
                    line.append(' '.join(p))
            line = ' '.join(line)
        else:                   # no strings, only array
            line = []
            for p in parts:
                if p: line += list(p)

        if not opts: opts = dict()
        if not def_opts: def_opts = dict()
        opts = def_opts | opts

        debug(f'which:run: {line} {opts=}')

        return run(line, **opts)
    return func

def log_command(dbfile, cmd, t1, t2, rc, args=None, opts=None, envs=None):
    '''
    Log a command.

    The command may be the name of an executable or a click command function.

    t1/t2 are timestamps bracketing the command.
    rc is return code.
    args list of command arguments.
    opts dict of any named command options.
    envs dict of any environment configurations (shell, or program config).
    '''

    args = args or []
    opts = opts or {}
    envs = envs or {}

    # dbfile = str(self.prefix / "wcwc.db")

    db = sqlite3.connect(dbfile)
    cur = db.cursor()

    # https://sqldocs.org/sqlite/sqlite-json-data/
    cur.execute('''CREATE TABLE IF NOT EXISTS commands(
    id INTEGER PRIMARY KEY,
    cmd TEXT,
    t1 TIMESTAMP,
    t2 TIMESTAMP,
    rc INTEGER,
    user TEXT,
    host TEXT,
    args JSON,
    opts JSON,
    envs JSON)''')
    
    if rc:
        try:
            rc = int(rc)
        except TypeError:
            rc = 1
    else:
        rc = 0

    user = getuser()
    host = gethostname()

    cur.execute('''INSERT INTO
    commands(cmd, t1, t2, rc, user, host, args, opts, envs)
    VALUES (?,?,?,?,?,?,?,?,?)''', (cmd, t1, t2, rc, user, host,
                                    json.dumps(args), json.dumps(opts), json.dumps(envs)))
    db.commit()
    log.debug(f'{cmd} ( {args}, {opts} )')


def assure_git_repo(path, branch, url=None, ref=None, remote=None):
    '''
    Assure there is a git repo at given path on given branch.

    A URL is required to clone.  If repo exists, URL is set as the given remote.

    If branch needs creating, a ref must be provided.  It may be a commit hash,
    a tag, a local or a remote branch.  If omitted, the value of "branch" is tried.
    '''
    path = Path(path)
    git = which("git", cwd=path)
    remote = remote or "origin"

    if path.exists():
        if url:
            git(f"remote set-url {remote} {url}")  # assure url
        debug(f"git fetching in {path}")
        git("fetch")
    else:
        if not url:
            raise click.UsageError(f"must supply URL to clone repo to {path}")
        debug(f"git cloning {url} to {path}")
        path.parent.mkdir(parents=True, exist_ok=True)
        git(f"clone -c feature.manyFiles=true {url} {path}", cwd=path.parent)

    # reset git so we check for error
    git = which("git", cwd=path, capture_error=False)

    current_branch = git("rev-parse --abbrev-ref HEAD", lines=1)
    debug(f'checking branch: {current_branch=} {branch=}')
    if branch == current_branch:
        debug(f"On branch {branch}, pulling")
        git("pull")
        return

    # see if branch is local branch
    rc = git(f'show-ref --verify --quiet refs/heads/{branch}')
    if not rc.returncode:
        debug(f"git switching to branch {branch}")
        git(f'switch {branch}')
        return

    # go fishing
    if not ref:
        ref = branch
    
    # try ref as commit'ish (tag, hash, branch)
    got = git(f'cat-file -t {ref}', lines=1)
    if got == "commit":
        debug(f"git checkout of local {ref} in {path}")
        git(f'checkout -b {branch} {ref}')
        return

    # try ref as remote branch
    got = git(f'cat-file -t {remote}/{ref}', lines=1)
    if got == "commit":
        debug(f"git checkout of remote {ref} in {path}")
        git(f'checkout -b {branch} {ref}')
        return
    
    raise click.UsageError(f"Can not assure branch {branch} in {path}")



def merge_patch(target, patch):
    '''
    Patch target and return result.

    https://datatracker.ietf.org/doc/html/rfc7396

    '''
    if isinstance(patch, dict):
        if not isinstance(target, dict):
            target = dict()
        for k,v in patch.items():
            if v is None:
                if k in target:
                    target.pop(k)
            elif k in target:
                target[k] = merge_patch(target[k], v)
            else:
                target[k] = v
        return target
    return patch


def merge_dicts(dict1, dict2):
    """ Recursively merges dict2 into dict1 """
    if not isinstance(dict1, dict) or not isinstance(dict2, dict):
        return dict2
    for k in dict2:
        if k in dict1:
            dict1[k] = merge_dicts(dict1[k], dict2[k])
        else:
            dict1[k] = dict2[k]
    return dict1

class SafeDict(dict):
    def __missing__(self, key):
        return '{' + key + '}'

def format_lazy(string, **kwds):
    '''
    Format string on interpolants in kwds.

    Any {...} interpolants not satisfied are kept.

    The values of kwds may themselves have {...} interpolants and the formatting
    proceeds until stability is reached.  

    Note, some Spack variables are objects and attempting to lazy format things
    like {compiler.name} fail as Python is trying to look for attribute "name"
    on string "compiler" even before asking SafeDict for missing.
    '''
    while True:
        try:
            new = string.format_map(SafeDict(**kwds))
        except AttributeError:
            return string
        if new == string:
            return string
        string = new

class Object:
    def __init__(self, prefix, cfg, defaults):
        self.prefix = prefix
        self._cfg = cfg or {}
        self._def = defaults or {}       

    @property
    def cfg(self):
        'Get full configuration dictionary'
        return merge_patch(dict(self._def), self._cfg)

    def keys(self):
        return set(list(self._cfg.keys()) + list(self._def.keys()))

    def path(self, kind, default="{prefix}/stacks/{stack}/{kind}", as_string=False):
        '''
        Return a path of a certain kind (repo, scope, environment, source)

        These are configuration keys like "{kind}_path".  If not found, the
        default value is returned.

        Values are interpolated with only {prefix} and {stack}.  Other
        interpolants are left as found.
        '''
        p = Path(self.get(kind + '_path', default, kind=kind))
        if as_string:
            p = str(p)
        return p

    def merge(self, **patch):
        '''
        Merge patch 
        '''
        if patch:
            self._cfg = merge_patch(self._cfg, patch)

    def setdefault(self, key, val):
        '''
        Set val on config if it is not already set.  Return val
        '''
        if key in self.keys():
            return
        self._cfg[key] = val
        return val

    def set(self, key, value):
        '''
        Set config value on key, return value.
        '''
        self._cfg[key] = value
        return value        

    def get(self, key, default=None, **kwds):
        '''
        Get value at key or return default.

        If value is type str it is interpolated against other config values.
        '''
        val = self.cfg.get(key, default)
        if not isinstance(val, str):
            return val
        # debug(f"Object.get {key=} {val=}")
        more = self.cfg | kwds
        return format_lazy(val, prefix=self.prefix, stack=self.name, **more)


    def init(self, wcwc, recurs=False):
        '''
        Initialize a scope/stack including getting source if a URL is specified.

        This configures the files.

        - config.yaml
        - concretizer.yaml

        Subclasses are encouraged to extend this method.

        '''
        if recurs:
            for dep in self.get("depends",[]):
                wcwc.stacks[dep].init(wcwc, recurs)

        debug(f'initializing stack "{self.name}"')

        if self.get("url", None):
            # if a stack's git repo and spack repo are not coincident then the
            # stack must supply a source_path for the git repo and repo_path is
            # assumed to be a sub-directory.
            spath = self.get("source_path", None)
            if spath is None:
                spath = self.get("repo_path")
            spath = Path(spath)

            ref = self.get("tag", "master")
            branch = self.get("branch", f'wcwc-{ref}')

            assure_git_repo(spath, branch=branch, url=self.get("url"),
                            ref=ref, remote=self.get("remote","origin"))

        config_dat = {
            "build_stage": ['$user_cache_path/stage'],
            "install_tree":  {
                "root": self.get("install_tree"),  # must have
                "projections": {
                    "all": self.get("projection")  # must have
                }
            }
        }
        er = self.get("environments_path")
        if er:
            config_dat["environments_root"] = er
        self.scope_config("config.yaml", dict(config=config_dat))

        # overrides for concretizer.yaml
        concretizer_dat = {
            "targets": {
                "granularity": self.get("granularity")  # must have
            }
        }
        self.scope_config("concretizer.yaml", dict(concretizer=concretizer_dat))


    def scope_config(self, fname, dat):
        '''
        Incorporate dat into scope config file fname.
        '''
        scope_path = self.path("scope")
        path = scope_path / fname
        if path.exists():
            old_dat = yaml.safe_load(path.read_text())
            dat = merge_patch(dat, old_dat)

        path.parent.mkdir(parents=True, exist_ok=True)
        path.write_text(yaml.dump(dat, sort_keys=False))
        debug(f'wrote file: {path}')
        

class Stack(Object):
    '''
    A stack is an association of a scope, repo, (system) environments and
    install tree.

    Stacks form a dependency tree.  A stack on which this stack depends that
    also has a unique install tree is additionally an "upstream".

    See also the Spack class which is a special kind of Stack.
    '''

    def __init__(self, name, prefix, cfg=None, **defaults):
        '''
        Create a model of a stack.

        Defaults are configuration that is not changed but is patched into cfg.

        Configuration values may have {prefix} or {stack} or Spack interpolants.
        '''
        super().__init__(prefix, cfg, defaults)
        self.name = name
        ### Use Object.path(kind) for f'{kind}_path'
        # for kind in "repo scope environments".split():
        #     self.setdefault(kind + '_path', "{prefix}/stacks/{stack}/"+kind)

    @property
    def deps(self):
        'Return list of names of stacks on which this one depends'
        return self.get("depends", [])

    def upstreams(self, wcwc):
        '''
        Return all deps as stack objects that have different install_tree than self.
        '''
        my_it = self.get("install_tree")
        return [s for s in self.dependencies(wcwc) if s.get("install_tree") == my_it]

    def dependencies(self, wcwc):
        '''
        Return all deps as stack objects
        '''
        return [wcwc.stacks[dep] for dep in self.deps]

        
    def init(self, wcwc, recurs=False):
        '''
        Assure the stage scope is configured accordingly

        - repos.yaml
        - upstreams.yaml
        - config.yaml (Object)
        - concretizer.yaml (Object)
        '''
        super().init(wcwc, recurs)      # Object

        self.scope_config("repos.yaml", dict(repos=[self.get("repo_path")]))

        for dep in self.upstreams(wcwc):
            self.scope_config("upstreams.yaml", {
                "upstreams": {
                    dep.name: {
                        "install_tree": dep.get("install_tree")
                    }
                }
            })


class Spack(Object):
    '''
    Abstract Spack as a stack-like thing with extra functionality. 

    As a stack, this has no dependencies.  It's "builtin" repo can be used or
    ignored or used in another stack to associate a unique scope, env list,
    install area.

    This class also provides extra methods for using the "spack" program.
    '''

    def __init__(self, prefix, cfg, defaults):
        super().__init__(prefix, cfg, defaults)

        self.name = "spack"     # mimic a Stack

        # we can hard-wire more defaults than with a general stack.
        self.setdefault("tag", "develop")
        self.setdefault("url", "https://github.com/spack/spack.git")
        self.setdefault("source_path", "{prefix}/spack")
        self.setdefault("repo_path", "{prefix}/spack/var/spack/repos/builtin")
        self.setdefault("remote", "develop")

    def execfunc(self, args=None, stacks=None, **kwds):
        '''
        Return spack command function that runs "args".

        The spack (sub) command is given by args and may be a string or a list
        and does not include "spack" itself.

        The stacks may be a list of stack objects from which a scope dir will be
        taken.

        kwds are passed directly to subprocess.
        '''
        extra = list()
        for stack in stacks or ():
            extra += ["-C=" + str(stack.path("scope"))]

        cli = extra
        if isinstance(args, str):  # stringify
            extra = ' '.join(extra)
            cli = f'{extra} {args}'
        elif args:              # assume list'ish
            cli = extra + list(args)
        
        return which(self.path("source") / "bin" / "spack", cli, **kwds)

    def command(self, cmd, stacks=None, **kwds):
        '''
        Execute a spack command.

        See execfunc() for arguments docs.
        '''
        return self.execfunc(cmd, stacks=stacks, **kwds)()
        
class WCWC:
    def __init__(self, prefix, config):
        self.prefix = Path(prefix or "/wcwc")
        self._cfg_path = Path(config or self.prefix / wcwc_config_filename)
        if self._cfg_path.exists():
            cfg = yaml.safe_load(self._cfg_path.read_text())
            debug(f'configuration: {self._cfg_path}')
        else:
            cfg = yaml.safe_load(default_config_yaml)
            debug('configuration: defaults')
            
        self._defaults = cfg.get("defaults",{})
        scfgs = cfg.get("stacks",{})
        self.stacks = {snam:Stack(snam, self.prefix, scfg, **self._defaults)
                       for snam,scfg in scfgs.items() if snam != "spack"}

        self.stacks["spack"] = Spack(self.prefix, scfgs.get("spack",{}), self._defaults)
        
    @property
    def spack(self):
        return self.stacks["spack"]

    @property
    def cfg(self):
        'Serialize to dict'
        return dict(defaults = self._defaults,
                    stacks = {n:s._cfg for n,s in self.stacks.items()})

    def dependency_graph(self, *seeds):
        '''
        Return dependency graph of stack names.

        Seeds may be stack objects or names
        '''
        gr = dict()
        for seed in seeds:
            if isinstance(seed, str):
                seed = self.stacks[seed]

            gr[seed.name] = set(list(getattr(seed,"deps",[])))
            gr |= self.dependency_graph(*gr[seed.name])
        return gr
            
    def dependency_list(self, *seeds, first=True):
        '''
        Return a flat, ordered list of stack names of the dependencies.
        '''
        gr = self.dependency_graph(*seeds)
        return list(graphlib.TopologicalSorter(gr).static_order())


    def save(self, output=None, overwrite=False):
        '''
        Save current state to our cfg_file unless output is given.

        If output is special "-", then write to stdout else output provides
        the name of file to which the state is written.
        '''
        text = yaml.dump(self.cfg, sort_keys=False)
        if output in ("-", "/dev/stdout"):
            print(text)
            return
        if not output:
            output = self._cfg_path
        else:
            output = Path(output)
        if output.exists() and not overwrite:
            raise click.UsageError(f'will not overwrite existing file: {output}.  Maybe try "-" as file name?')

        output.parent.mkdir(parents=True, exist_ok=True)
        output.write_text(text)
        debug(f'wrote {output}')

    def set_stack(self, name, **kwds):
        '''
        Define or update a stack of given name by patching kwds.

        Return object
        '''
        if name in self.stacks:
            stack = self.stacks[name]
            stack.merge(**kwds)
            return stack
        
        ret = self.stacks[name] = Stack(name, self.prefix, kwds, **self._defaults)
        return ret

        # scfg = self._cfg.get('stacks',{}).get(name, {})
        # self._cfg['stacks'][name] = merge_patch(dict(scfg), kwds)
        
    def assure_yaml(self, path, dat, force=False):
        path = Path(path)
        if path.exists() and not force:
            debug(f'not writing existing file: {path}')
            return
        path.parent.mkdir(parents=True, exist_ok=True)
        path.write_text(yaml.dump(dat, sort_keys=False))
        debug(f'wrote file: {path}')

    def paths(self, name):
        '''
        Return all canonical paths for stack.
        '''
        

        root = self.prefix / "spack" / name
        more = {k:root/k for k in "scope repo install environments".split()}
        more['git'] = root / "repo" / ".git"
        if name == "base":
            # Connect with Spack's structure that differs from how WCWC handles
            # others.  "repo" refers to Spack repo not git repo though these two
            # coincide for the "chained" repos.
            more['repo'] = more['repo'] / "var" / "spack" / "repos" / "builtin"
        return namedtuple("Paths", "root scope repo install environments git")(root=root, **more)


    def log_command(self, name, t1, t2, rc, args, opts):
        dbfile = str(self.prefix / "wcwc.db")
        log_command(dbfile, name, t1,t2,rc,args,opts,self.cfg)


def setup_logging(log_output, log_level):
    try:
        level = int(log_level)      # try for number
    except ValueError:
        level = log_level.upper()   # else assume label
    log.setLevel(level)

    if not log_output:
        log_output = ["stderr"]
    for one in log_output:
        if one in ("stdout", "stderr"):
            sh = logging.StreamHandler(getattr(sys, one))
            sh.setLevel(level)
            log.addHandler(sh)
            continue
        fh = logging.FileHandler(one)
        fh.setLevel(level)
        log.addHandler(fh)

    debug(f'logging to {log_output} at level {log_level}')


# CLICK command line user interface

cmddef = dict(context_settings = dict(auto_envvar_prefix='WCWC',
                                      help_option_names=['-h', '--help']))
@click.option("-c", "--config", default=None, type=str,
              help="Specify a config file")
@click.option("-p", "--prefix", default=None, type=str,
              help="Specify WCWC Spack installation prefix (def=/wcwc)")
@click.option("-l","--log-output", multiple=True,
              help="log to a file [default:stdout]")
@click.option("-L","--log-level", default="info",
              help="set logging level [default:info]")
@click.group("wcwc", **cmddef)
@click.pass_context
def cli(ctx, config, prefix, log_output, log_level):
    setup_logging(log_output, log_level)
    ctx.obj = WCWC(prefix, config)


def use_stacks(with_spack=True, required=False):
    '''The command uses one or more stacks'''
    def decorator(func):
        @click.option("-S", "--stacks", default=None, type=str,
                      help="Set stacks to use as comma separated list")
        @click.pass_context
        @functools.wraps(func)
        def wrapper(ctx, stacks, *args, **kwds):
            debug(f'use_stacks: {stacks}')
            if stacks is None:
                stacks = ()
            elif stacks in ("all","known"):
                stacks = list(ctx.obj.stacks.values())
                debug(f'use_stacks: {[s.name for s in stacks]}')
            else:
                stacks = [ctx.obj.stacks[s] for s in stacks.split(",")]
                debug(f'use_stacks: {[s.name for s in stacks]}')

            if required:
                for stack in stacks:
                    for kind in ("scope", "repo"):
                        path = stack.path(kind)
                        if path.exists():
                            continue
                        raise click.UsageError(f"required stack lacks: {path}.  Try 'wcwc init -n {stack.name}'?")

            kwds['stacks'] = stacks
            if with_spack:
                spack_exe = ctx.obj.spack.execfunc(
                    stacks=stacks, capture_error=False,
                    capture_output=False, check=False)
                kwds['spack_exe'] = spack_exe

            return func(*args, **kwds)
        return wrapper
    return decorator


def set_a_stack(with_spack=True):
    '''The command deals with a stack allowing re definition'''
    def decorator(func):
        @click.option("--tag",default=None, type=str, 
                      help=f"override default git tag (tag/hash/branch)")
        @click.option("--branch",default=None, type=str,
                      help=f"override default branch")
        @click.option("--url",default=None, type=str,
                      help=f"override default git url")
        @click.option("--remote",default="origin",
                      help=f"override the git remote name")
        @click.option("--source-path",default=None, type=str,
                      help=f"override source path to stack source")
        @click.option("--repo-path",default=None, type=str,
                      help=f"override source path to stack source")
        @click.option("--depends",default=None, type=str,
                      help=f"override dependency stacks (comma separated list)")
        @click.argument("name")
        @click.pass_context
        @functools.wraps(func)
        def wrapper(ctx, name, tag, branch, url, remote, source_path, repo_path, depends, *args, **kwds):
            stack = ctx.obj.set_stack(name)
            kwds['stack'] = stack


            if tag:
                stack.set("tag", tag)
            if branch:
                stack.set("branch", branch)
            if url:
                stack.set("url", url)
            if remote:
                stack.set("remote", remote)
            if source_path:
                stack.set("source_path", source_path)
            if repo_path:
                stack.set("repo_path", repo_path)
            if depends:
                stack.set("depends", depends)

            if with_spack:
                spack_exe = ctx.obj.spack.execfunc(
                    stacks=[stack], capture_error=False,
                    capture_output=False, check=False)
                kwds['spack_exe'] = spack_exe

            return func(*args, **kwds)
        return wrapper
    return decorator


def admin_command(name=None, **cmddef):
    '''
    Return a decorator for any WCWC admin command.

    This logs the command to the db.
    '''
    def decorator(func):
        @cli.command(name, **cmddef)
        @click.pass_context
        @functools.wraps(func)
        def wrapper(ctx, *args, **kwds):

            try:
                ctx.obj.prefix.mkdir(parents=True, exist_ok=True)
            except PermissionError:
                raise click.UsageError(f"no permission create {ctx.obj.prefix}, give --prefix or set WCWC_PREFIX")


            if not os.access(ctx.obj.prefix, os.W_OK):
                raise click.UsageError(f"no write permission to {ctx.obj.prefix}, give --prefix or set WCWC_PREFIX")

            t1 = datetime.now()
            got = func(*args, **kwds)
            t2 = datetime.now()
            
            ctx.obj.log_command(name or ctx.info_name, t1, t2, got, args, kwds)
            ctx.obj.save(overwrite=True)
            return got
        return wrapper
    return decorator
    


#@cli.command("junk")
@admin_command()
@click.option("-p", "--prefix", default=None, type=str)
@click.option("--throw", is_flag=True, default=False)
@click.pass_context
def junk(ctx, prefix, throw):
    '''
    Ignore this cmd, it is to test out click stuff.
    '''
    info(f'junk: {prefix=}')
    info(ctx.obj.cfg)
    if throw:
        raise ValueError("throwing")
    return


@cli.command("dump-config")
@click.option("-f","--force-overwrite", is_flag=True, default=False,
              help="Allow to overwrite existing file")
@click.argument("output", nargs=-1)
@click.pass_context
def dump_config(ctx, output, force_overwrite):
    '''
    Emit a default config file.

    By default, the config file is written under --prefix.
    An argument of "-" will write to stdout.
    Any other argument will be interpreted as a file name.
    '''
    if output:
        output = output[0]
    ctx.obj.save(output, overwrite=force_overwrite)


@cli.command("check-stacks")
@click.pass_context
def check_stacks(ctx):
    '''
    Show status about existence of known stacks.
    '''
    git = which("git")

    for stack in ctx.obj.stacks.values():
        path = stack.path("repo")
        if path.exists():
            ver = git(f'rev-parse --abbrev-ref HEAD', lines=1, cwd=str(path))
            info(f'{stack.name:20} {ver}')
        else:
            info(f'{stack.name:20} (missing: {path})')

@cli.command("check-os")
def check_os():
    """Check if current running OS is supported"""
    got = run("lsb_release -ds", lines=1)
    if got in known_oses:
        return
    raise ValueError(f'not a supported OS: {got}')

@cli.command("list-os")
def list_os():
    '''
    Print names of supported operating systems, one per line.
    '''
    for one in known_oses:
        info(one)


@admin_command("spack", context_settings=dict(ignore_unknown_options=True,
                                            help_option_names=[]))
@use_stacks()
@click.argument("args", nargs=-1, type=click.UNPROCESSED)
@click.pass_context
def spack(ctx, stacks, spack_exe, args):
    '''
    A wrapper around spack for WCWC admins.

    This adds some WCWC specific functionality including:
    - logging the command to the command DB
    - resolving a stack name to its scope

    WCWC admins should use this instead of bare "spack" for any tasks that
    involve modifying the Spack installation.
    '''
    got = spack_exe(args)
    return got.returncode


@cli.command("list-env")
@use_stacks(required=False, with_spack=False)
@click.pass_context
def list_environments(ctx, stacks):
    '''
    List the defined system/shared environments.
    '''
    stacks = [ctx.obj.stacks[sn] for sn in ctx.obj.dependency_list(*stacks)]
    for stack in stacks:
        if not stack.path("scope").exists():
            continue

        print(f'{stack.name}:')
        got = ctx.obj.spack.command("env list", stacks=[stack],
                                    capture_error=False, capture_output=False, check=False)
        if got.returncode:
            return got.returncode
        print()
        


@cli.command("list-scope")
@click.pass_context
def list_scope(ctx):
    '''List known scopes'''
    for name, dat in ctx.obj.cfg['repos'].items():
        paths = ctx.obj.paths(name)
        url=dat.get('url','')
        tag=dat.get('tag','')
        us=','.join(dat.get('upstreams',[]))
        exist = "installed" if paths.scope.exists() else "missing"
        info(f'{name:12} {paths.scope} ({exist}) {tag}')




@cli.command("show")
@click.option("-f","--format", default="yaml",
              help="format to output print")
@use_stacks(with_spack=False)
@click.pass_context
def show(ctx, format, stacks):
    '''
    Show information about a stack.
    '''
    for stack in stacks:
        if format == "yaml":
            info (yaml.dump(stack.cfg, sort_keys=False))
        else:
            info (str(stack.cfg))
    

@admin_command("install")
@click.option("-S","--stack", default=None, type=str, required=True,
              help="The name of the stack in which to perform the installation")
@click.argument("specs", nargs=-1)
@click.pass_context
def install(ctx, stack, specs):
    '''
    Install a package in the context of a stack.

    This is a thin wrapper around "spack install" that makes sure to do the
    installation in the scope for a stack.
    '''
    if stack not in ctx.obj.stacks:
        raise click.UsageError(f'uknown stack: "{stack}"')

    got = ctx.obj.spack.command(["install"]+list(specs), stacks=[ctx.obj.stacks[stack]],
                                capture_error=False, capture_output=False)
    return got.returncode
    
@admin_command("make-sys-env")
@click.option("-S","--stack", default=None, type=str, required=True,
              help="The name of the stack in which to perform the installation")
@click.option("-n", "--name", default=None, type=str, required=True,
              help="The name of the system environment")
@click.argument("specs", nargs=-1)
@click.pass_context
def make_sys_env(ctx, stack, name, specs):
    '''
    Create a named system/shared environment.

    This command is idempotent.
    '''
    if stack not in ctx.obj.stacks:
        raise click.UsageError(f'uknown stack: "{stack}"')

    stack = ctx.obj.stacks[stack]
    spack_exe = ctx.obj.spack.execfunc(stacks=[stack], capture_output=False)

    envcfg = stack.path("environments") / name / "spack.yaml"
    if not envcfg.exists():
        spack_exe(f'env create {name}')

    # If I do not munge the env the install quietly fails to populate the view.
    # This might be a bug, or at least a dubious feature.
    env = dict(os.environ)
    env["SPACK_ENV_VIEW"] = "default"
    env["SPACK_ENV"] = str(envcfg.parent)
    for spec in specs:
        spack_exe(f'install --add {spec}', env=env)



@admin_command("init")
@click.option("--recurs", is_flag=True, default=True,
              help="recurs over upstreams, if any (default=False)")
@click.option("--force", is_flag=True, default=False,
              help="force overwriting (default=False)")
@set_a_stack(with_spack=False)
@click.pass_context
def init(ctx, recurs, force, stack):
    '''
    Initialize support for the named stack.

    Spack itself is represented by the stack named "spack".

    If the stack name is not known in defaults or in the configuration file then
    it must be sufficiently described.

    If recurs is True (default), stacks on which the named stack depends will
    also be initialized.  Dependencies must be known.

    No actual Spack packages are installed.  See "wcwc install"

    This command is idempotent.
    '''
    debug(f"initialize stack: {stack.name}")
    stack.init(ctx.obj, recurs)
    

@cli.command("spack-shell")
@click.option("-s", "--shell",
              default="auto",
              type=click.Choice(["sh","bash","dash","zsh","fish","csh","tcsh","auto"]),
              help="Set the shell flavor, default:auto")
@click.option("-e", "--execute", is_flag=True, default=False,
              help="Execute subshell in the environment instead of emitting shell environment settings")
@click.option("-c", "--command", type=str, default=None,
              help="Execute the command in a configured subshell")
@click.pass_context
def spack_shell(ctx, shell, execute, command):
    '''
    Configure shell environment to use spack.

    This is a user command.  WCWC admins should not use this to modify the WCWC
    installation.

    It may be used to configure your shell environment like:

      eval (wcwc spack-shell)    # fish
      eval $(wcwc spack-shell)   # sh-like
      eval `wcwc spack-shell`    # csh-like

    Do NOT log to standard output ("-L stdout") with the above usage.

    Or to execute a subshell:

      wcwc spack-shell -e
      # ...
      exit 

    Or to execute a specific command and return to your original shell.

      wcwc spack-shell -c "which spack"

    FIXME: support for "spack env" and "spack load" env munging
    '''

    if shell == "auto":
        shell = os.environ.get("SHELL",None)
        if not shell:
            user = os.environ.get("USER", run("id -u -n", lines=1))
            shell = run(f"getent passwd {user}", lines=1).split(":")[6]
        if not shell:
            raise ValueError("can not divine shell, give it explicitly")
    shell = shell.split("/")[-1].strip()

    ext = dict(sh="sh",bash="sh",dash="sh",zsh="sh",fish="fish",csh="csh",tcsh="csh")[shell]
    script = ctx.obj.spack.path("source")  / "share" / "spack" / f"setup-env.{ext}"
    script = str(script)

    if execute:
        if shell == "bash":
            cmd=["bash","--rcfile", script]
            debug(f'execute: {" ".join(cmd)}')
            os.execvp("bash", cmd)  # does not return
        if shell == "fish":
            os.execvp("fish", ["fish","-C", f"source {script}"])  # does not return

        raise click.UsageError(f'execute unsupported for shell: "{shell}"')
        
    if command:
        if shell == "bash":
            command = f'source {script} && {command}'
            os.execvp("bash", ["bash", "-c", command])  # does not return
        if shell == "fish":
            os.execvp("fish", ["fish","-C", f"source {script}", "-c", command])  # does not return
        raise click.UsageError(f'command unsupported for shell: "{shell}"')

    envset = script.read_text()
    print(envset)           # print() not info()

    

@cli.command("make-dev-env")
@click.option("-S","--stacks",default=None, type=str,
              help="comma separated list of stacks")
@click.argument("path")
@click.pass_context
def make_dev_env(ctx, upstreams, path):
    '''
    Create a developer environment.

    Once activated, packages may be installed locally or added from the stacks.
    '''

    path = Path(path).absolute()
    if path.exists():
        debug(f'devenv: exists at {path}')
    else:
        ctx.obj.spack.command(f'env create --dir {path}')

    spack_yaml = path / "spack.yaml"

    dat = dict()

    if upstreams:
        upstreams = upstreams.split(",")
        upstreams = ctx.obj.resolve_upstreams(*upstreams)
        upstreams.reverse()

        dat["upstreams"] = dict()
        dat["repos"] = list()
        it_seen = set()
        for name in upstreams:
            paths = ctx.obj.paths(name)
            it = str(paths.install)
            if it not in seen:
                dat["upstreams"][name] = dict(install_tree=it)
            it_seen.add(it)
            dat["repos"].append(str(paths.repo))

    dat["config"] = dict(
        install_tree=dict(root=str(path / "install")),
        build_stage=[str(path / "stage")],
        source_cache=str(path / "cache"))

    old_dat = yaml.safe_load(spack_yaml.read_text())
    new_dat = merge_patch(old_dat, dict(spack=dat))
    spack_yaml.write_text(yaml.dump(new_dat, sort_keys=False))
    debug(f"devenv made at {path.absolute()} with upstreams {upstreams}")
    info(f'Activate with:\n\tsource `wcwc spack-setup`\n\tspack env activate {path.absolute()}')

if '__main__' == __name__:
    cli()
