#!/usr/bin/python3
# NOT /usr/bin/env python as we want OS python always
'''
Utility to create, manage and use elements of a Wire-Cell Workstation Cluster.

Largely a wrapper around spack and podman.
'''

wcwc_version = "0.0.2"


import os
import sys
import json
import yaml
from datetime import datetime
import click
import shutil
from socket import gethostname
from getpass import getuser
import graphlib
import tempfile
import functools
from pathlib import Path
from collections import namedtuple

import logging
log = logging.getLogger("wcwc")
debug = log.debug
info = log.info
warn = log.warn
error = log.error


# Code may use parts of subprocess 
from subprocess import STDOUT, PIPE, CalledProcessError


# The (default) directory holding all things WCWC.  This can be changed with group-level -p/--prefix option.
wcwc_prefix = "/wcwc"

# The name of the config file that will be read/written under <prefix>/
wcwc_config_filename = "wcwc.yaml"

# The (default) name for a podman image used to provide run time environment.
wcwc_image = "wcwc-image"


# Default config object which may be overridden by a config file.
#
# The config largely consists of a description of a list of WCWC "stacks".
# 
# A WCWC "stack" consists of:
# - A Spack "package repo" taken from a git repo at a particular tag/branch.
# - The set of packages installed from the repo.
# - A Spack "scope".
# - A set of Spack Environments.
#
# A stack may depend on other stacks.  When a stack and dependency stack do not
# share the same install_tree then the dependency is considered an "upstream"
# Spack installation and will be "chained".  Otherwise, the dependency is
# implicit.  A WCWC stack name is also a Spack namespace and thus separation of
# stack packages can be achived using '{namespace}' in the projection.  Note,
# when upstream chaining is used, all packages are installed into the stack's
# install_tree even if they are provided by dependency repos.
# 
# Note, that the use of the Spack "builtin" repo is not implicit in wcwc
# commands.  This allows a setup that elides the builtin repo entirely or one
# that allows the builtin repo to be updated independently from the Spack
# source.  That said, default configuration includes a "base" stack that points
# to the Spack "builtin" repo.  In addition, as the user will inevitably issue
# bare "spack" commands and not set the configuration scope to a stack scope,
# the various configurations relevant to the builtin repo are set on the Spack
# instance.
#
# The configuration values may use WCWC and Spack variables.
# WCWC variables include {prefix} and {stack} and all others are Spack's.
default_config_yaml = '''
defaults:
  install_tree: "{prefix}/opt"
  projection: "{namespace}/{architecture}/{compiler.name}-{compiler.version}/{name}-{version}-{hash}"
  granularity: generic
  repo_path: "{prefix}/stacks/{stack}/repo"
  scope_path: "{prefix}/stacks/{stack}/scope"
  environments_path: "{prefix}/stacks/{stack}/environments"

stacks:
  spack:
    url: "https://github.com/spack/spack.git"
    tag: "v0.22.1"
    source_path: "{prefix}/spack"
    scope_path: "{source_path}/etc/spack"
    repo_path: "{source_path}/var/spack/repos/builtin"

  base:
    repo_path: "{prefix}/spack/var/spack/repos/builtin"
    depends:
    - spack

  wirecell:
    url: "https://github.com/WireCell/wire-cell-spack.git"
    tag: "0.28.0.2"
    depends:
    - base

  nusoft:
    url: "https://github.com/NuSoftHEP/nusofthep-spack-recipes.git"
    depends:
    - base

  art:
    url: "https://github.com/FNALssi/fnal_art.git"
    depends:
    - nusoft

  larsoft:
    url: "https://github.com/LArSoft/larsoft-spack-recipes.git"
    depends:
    - art
'''

# A hard-wired list of OSes supported by this version of WCWC.
# These are "spelled" as the output of "lsb_release -ds".
known_oses=("Debian GNU/Linux 12 (bookworm)",)

def run(cmd, lines=None, capture_error=True, **opts):
    '''
    Apply default policy to subprocess.run() to execute "cmd"

    If lines provides an integer, stdout is decoded to string and up to that
    many newline-delimited lines are returned instead of a CompletedProcess
    object.  The end of the string does NOT have a new line.

    If capture_error is true (default) then an error return code will lead to
    the stdout and stderr being logged prior to throwing.

    capture_output option is True by default and is passed to subprocess.  Set
    to False if you want stdout/stderr to not be captured and flow freely to the
    terminal.

    check option is False by default and passed to subprocess.  Set to True to
    make subprocess check the rc and maybe throw.  However, if capture_error is
    True, subprocess will be told to not check and instead, we check locally.
    '''
    from subprocess import run as srun
    if isinstance(cmd, str):
        opts["shell"]=True
    opts.setdefault("capture_output", True)
    opts.setdefault("check", False)
    if capture_error:
        opts["check"] = False
    debug(f'exec: {cmd=} {opts=}')
    if not isinstance(cmd,str):
        debug(' '.join(cmd))
    rc = srun(cmd, **opts)  # throws

    if lines is None and capture_error and rc.returncode:
        error(f'command failed: {cmd}')
        out = rc.stdout.decode() if rc.stdout else ""
        error(f'output:\n{out}')
        err = rc.stderr.decode() if rc.stderr else ""
        error(f'error:\n{err}')
        rc.check_returncode()   # raise the exception
    else:                       # try to do normal logging
        if rc.stdout:
            debug(rc.stdout.decode())
        if rc.stderr:
            debug(rc.stderr.decode())

    if lines is None:
        return rc
    return '\n'.join(rc.stdout.decode().strip().split("\n")[:lines])


def which(exe, def_args=None, **def_opts):
    '''
    Find executable file "exe" and return a function that may be called like:

        func(args=None, **opts)

    Any args are appended to def_args.  If either args or def_args are string,
    the resulting command is string and executed by the shell.  If both args and
    def_args are list, the command is a list and may be directly executed unless
    shell=True option is passed.

    Any opts are merged into def_opts.

    When function func() is later called, the exe is executed with the accrued
    args and opts.  The opts are passed to run().
    '''
    path = shutil.which(str(exe))
    if path is None:
        raise FileNotFoundError(f'no such executable "{exe}"')
    if not os.access(path, os.X_OK):
        raise click.UsageError(f'not executable: {path}')
    
    debug(f'which: {exe=} {def_args=} {def_opts=}')

    def func(args=None, **opts):
        nonlocal def_args
        nonlocal def_opts

        parts = [[path], def_args, args]
        if any([isinstance(p,str) for p in parts]):
            # any a string, all a string
            line = list()
            for i,p in enumerate(parts):
                if isinstance(p, str):
                    line.append(p)
                elif p:
                    line.append(' '.join(p))
            line = ' '.join(line)
        else:                   # no strings, only array
            line = []
            for p in parts:
                if p: line += list(p)

        if not opts: opts = dict()
        if not def_opts: def_opts = dict()
        opts = def_opts | opts

        debug(f'which:run: {line} {opts=}')

        return run(line, **opts)
    return func



def assure_git_repo(path, branch, url=None, ref=None, remote=None):
    '''
    Assure there is a git repo at given path on given branch.

    A URL is required to clone.  If repo exists, URL is set as the given remote.

    If branch needs creating, a ref must be provided.  It may be a commit hash,
    a tag, a local or a remote branch.  If omitted, the value of "branch" is tried.
    '''
    path = Path(path)
    git = which("git", cwd=path)
    remote = remote or "origin"

    if path.exists():
        if url:
            git(f"remote set-url {remote} {url}")  # assure url
        debug(f"git fetching in {path}")
        git("fetch")
    else:
        if not url:
            raise click.UsageError(f"must supply URL to clone repo to {path}")
        debug(f"git cloning {url} to {path}")
        path.parent.mkdir(parents=True, exist_ok=True)
        git(f"clone -c feature.manyFiles=true {url} {path}", cwd=path.parent)

    # reset git so we check for error
    git = which("git", cwd=path, capture_error=False)

    current_branch = git("rev-parse --abbrev-ref HEAD", lines=1)
    debug(f'checking branch: {current_branch=} {branch=}')
    if branch == current_branch:
        debug(f"On branch {branch}, pulling")
        git("pull")
        return

    # see if branch is local branch
    rc = git(f'show-ref --verify --quiet refs/heads/{branch}')
    if not rc.returncode:
        debug(f"git switching to branch {branch}")
        git(f'switch {branch}')
        return

    # go fishing
    if not ref:
        ref = branch
    
    # try ref as commit'ish (tag, hash, branch)
    got = git(f'cat-file -t {ref}', lines=1)
    if got == "commit":
        debug(f"git checkout of local {ref} in {path}")
        git(f'checkout -b {branch} {ref}')
        return

    # try ref as remote branch
    got = git(f'cat-file -t {remote}/{ref}', lines=1)
    if got == "commit":
        debug(f"git checkout of remote {ref} in {path}")
        git(f'checkout -b {branch} {ref}')
        return
    
    raise click.UsageError(f"Can not assure branch {branch} in {path}")



def merge_patch(target, patch):
    '''
    Patch target and return result.

    https://datatracker.ietf.org/doc/html/rfc7396

    '''
    if isinstance(patch, dict):
        if not isinstance(target, dict):
            target = dict()
        for k,v in patch.items():
            if v is None:
                if k in target:
                    target.pop(k)
            elif k in target:
                target[k] = merge_patch(target[k], v)
            else:
                target[k] = v
        return target
    return patch

def yaml_merge_patch(path, patch):
    '''
    Apply patch to yaml file at path.

    Patch is a data structure.  If path does not exist, patch is written.
    '''
    path = Path(path)
    if path.exists():
        dat = yaml.safe_load(path.read_text())
        debug(f'yaml merge patch read: {path} {dat}')
        dat = merge_patch(dat, patch)
    else:
        path.parent.mkdir(parents=True, exist_ok=True)
        dat = patch
    debug(f'yaml merge patch write: {path} {dat}')
    path.write_text(yaml.dump(dat, sort_keys=False))
    

def merge_dicts(dict1, dict2):
    """ Recursively merges dict2 into dict1 """
    if not isinstance(dict1, dict) or not isinstance(dict2, dict):
        return dict2
    for k in dict2:
        if k in dict1:
            dict1[k] = merge_dicts(dict1[k], dict2[k])
        else:
            dict1[k] = dict2[k]
    return dict1

class SafeDict(dict):
    def __missing__(self, key):
        return '{' + key + '}'

def format_lazy(string, **kwds):
    '''
    Format string on interpolants in kwds.

    Any {...} interpolants not satisfied are kept.

    The values of kwds may themselves have {...} interpolants and the formatting
    proceeds until stability is reached.  

    Note, some Spack variables are objects and attempting to lazy format things
    like {compiler.name} fail as Python is trying to look for attribute "name"
    on string "compiler" even before asking SafeDict for missing.
    '''
    while True:
        try:
            new = string.format_map(SafeDict(**kwds))
        except AttributeError:
            return string
        if new == string:
            return string
        string = new

class Object:
    def __init__(self, prefix, cfg, defaults):
        self.prefix = prefix
        self._cfg = cfg or {}
        self._def = defaults or {}       

    @property
    def cfg(self):
        'Get full configuration dictionary'
        return merge_patch(dict(self._def), self._cfg)

    def keys(self):
        return set(list(self._cfg.keys()) + list(self._def.keys()))

    def path(self, kind, default="{prefix}/stacks/{stack}/{kind}", as_string=False):
        '''
        Return a path of a certain kind (repo, scope, environment, source)

        These are configuration keys like "{kind}_path".  If not found, the
        default value is returned.

        Values are interpolated with only {prefix} and {stack}.  Other
        interpolants are left as found.
        '''
        p = Path(self.get(kind + '_path', default, kind=kind))
        if as_string:
            p = str(p)
        return p

    def merge(self, **patch):
        '''
        Merge patch 
        '''
        if patch:
            self._cfg = merge_patch(self._cfg, patch)

    def setdefault(self, key, val):
        '''
        Set val on config if it is not already set.  Return val
        '''
        if key in self.keys():
            return
        self._cfg[key] = val
        return val

    def set(self, key, value):
        '''
        Set config value on key, return value.
        '''
        self._cfg[key] = value
        return value        

    def get(self, key, default=None, **kwds):
        '''
        Get value at key or return default.

        If value is type str it is interpolated against other config values.
        '''
        val = self.cfg.get(key, default)
        if not isinstance(val, str):
            return val
        # debug(f"Object.get {key=} {val=}")
        more = self.cfg | kwds
        return format_lazy(val, prefix=self.prefix, stack=self.name, **more)


    def init(self, wcwc, recurs=False):
        '''
        Initialize a scope/stack including getting source if a URL is specified.

        This configures the files.

        - config.yaml
        - concretizer.yaml
        - packages.yaml

        Subclasses are encouraged to extend this method.

        '''
        if recurs:
            for dep in self.get("depends",[]):
                wcwc.stacks[dep].init(wcwc, recurs)

        debug(f'initializing stack "{self.name}"')

        if self.get("url", None):
            # if a stack's git repo and spack repo are not coincident then the
            # stack must supply a source_path for the git repo and repo_path is
            # assumed to be a sub-directory.
            spath = self.get("source_path", None)
            if spath is None:
                spath = self.get("repo_path")
            spath = Path(spath)

            ref = self.get("tag", "master")
            branch = self.get("branch", f'wcwc-{ref}')

            assure_git_repo(spath, branch=branch, url=self.get("url"),
                            ref=ref, remote=self.get("remote","origin"))

        config_dat = {
            "build_stage": [f'{self.prefix}/stage'],
            "install_tree":  {
                "root": self.get("install_tree"),  # must have
                "projections": {
                    "all": self.get("projection")  # must have
                }
            }
        }
        er = self.get("environments_path")
        if er:
            config_dat["environments_root"] = er
        self.scope_config("config.yaml", dict(config=config_dat))

        # overrides for concretizer.yaml
        concretizer_dat = {
            "targets": {
                "granularity": self.get("granularity")  # must have
            }
        }
        self.scope_config("concretizer.yaml", dict(concretizer=concretizer_dat))

        # default packages config
        packages_dat = {
            "all": {
                "target": ["x86_64"]
            }
        }
        self.scope_config("packages.yaml", dict(packages=packages_dat))
        

    def scope_config(self, fname, dat):
        '''
        Incorporate dat into scope config file fname.
        '''
        scope_path = self.path("scope")
        path = scope_path / fname
        yaml_merge_patch(path, dat)

        # if path.exists():
        #     old_dat = yaml.safe_load(path.read_text())
        #     dat = merge_patch(dat, old_dat)

        # path.parent.mkdir(parents=True, exist_ok=True)
        # path.write_text(yaml.dump(dat, sort_keys=False))
        debug(f'wrote file: {path}')
        

class Stack(Object):
    '''
    A stack is an association of a scope, repo, (system) environments and
    install tree.

    Stacks form a dependency tree.  A stack on which this stack depends that
    also has a unique install tree is additionally an "upstream".

    See also the Spack class which is a special kind of Stack.
    '''

    def __init__(self, name, prefix, cfg=None, **defaults):
        '''
        Create a model of a stack.

        Defaults are configuration that is not changed but is patched into cfg.

        Configuration values may have {prefix} or {stack} or Spack interpolants.
        '''
        super().__init__(prefix, cfg, defaults)
        self.name = name
        ### Use Object.path(kind) for f'{kind}_path'
        # for kind in "repo scope environments".split():
        #     self.setdefault(kind + '_path', "{prefix}/stacks/{stack}/"+kind)

    @property
    def deps(self):
        'Return list of names of stacks on which this one depends'
        return self.get("depends", [])

    def upstreams(self, wcwc):
        '''
        Return all deps as stack objects that have different install_tree than self.
        '''
        my_it = self.get("install_tree")
        return [s for s in self.dependencies(wcwc) if s.get("install_tree") == my_it]

    def dependencies(self, wcwc):
        '''
        Return all deps as stack objects
        '''
        return [wcwc.stacks[dep] for dep in self.deps]

        
    def init(self, wcwc, recurs=False):
        '''
        Assure the stage scope is configured accordingly

        - repos.yaml
        - upstreams.yaml
        - config.yaml (Object)
        - concretizer.yaml (Object)
        '''
        super().init(wcwc, recurs)      # Object

        self.scope_config("repos.yaml", dict(repos=[self.get("repo_path")]))

        for dep in self.upstreams(wcwc):
            self.scope_config("upstreams.yaml", {
                "upstreams": {
                    dep.name: {
                        "install_tree": dep.get("install_tree")
                    }
                }
            })


class Spack(Object):
    '''
    Abstract Spack as a stack-like thing with extra functionality. 

    As a stack, this has no dependencies.  It's "builtin" repo can be used or
    ignored or used in another stack to associate a unique scope, env list,
    install area.

    This class also provides extra methods for using the "spack" program.
    '''

    def __init__(self, prefix, cfg, defaults):
        super().__init__(prefix, cfg, defaults)

        self.name = "spack"     # mimic a Stack

        # we can hard-wire more defaults than with a general stack.
        self.setdefault("tag", "develop")
        self.setdefault("url", "https://github.com/spack/spack.git")
        self.setdefault("source_path", "{prefix}/spack")
        self.setdefault("repo_path", "{prefix}/spack/var/spack/repos/builtin")
        self.setdefault("remote", "develop")

    def command_line(self, args=None, stacks=None):
        '''
        Build and return command line string for calling spack as tuple:

            (Path("/path/to/executable"), args_with_stacks)

        If args_with_stacks keeps same type as args (array or string) and has
        stacks added as Spack configuration scopes.

        '''
        extra = list()
        exe_path = self.path("source") / "bin" / "spack"

        for stack in stacks or ():
            extra += ["-C", str(stack.path("scope"))]

        cli = extra
        if isinstance(args, str):  # stringify
            extra = ' '.join(extra)
            cli = f'{extra} {args}'
        elif args:              # assume list'ish
            cli = extra + list(args)

        return (exe_path, cli)

    def execfunc(self, args=None, stacks=None, **kwds):
        '''
        Return spack command function that runs "args".

        The spack (sub) command is given by args and may be a string or a list
        and does not include "spack" itself.

        The stacks may be a list of stack objects from which a scope dir will be
        taken.

        kwds are passed directly to subprocess.
        '''
        path,cli = self.command_line(args, stacks)
        return which(path, cli, **kwds)

    def command(self, cmd, stacks=None, **kwds):
        '''
        Execute a spack command.

        See execfunc() for arguments docs.
        '''
        return self.execfunc(cmd, stacks=stacks, **kwds)()
        
class WCWC:
    def __init__(self, prefix, config):
        self.prefix = Path(prefix or wcwc_prefix)
        self._cfg_path = Path(config or self.prefix / wcwc_config_filename)
        if self._cfg_path.exists():
            cfg = yaml.safe_load(self._cfg_path.read_text())
            debug(f'configuration: {self._cfg_path}')
        else:
            cfg = yaml.safe_load(default_config_yaml)
            debug('configuration: defaults')
            
        self._defaults = cfg.get("defaults",{})
        scfgs = cfg.get("stacks",{})
        self.stacks = {snam:Stack(snam, self.prefix, scfg, **self._defaults)
                       for snam,scfg in scfgs.items() if snam != "spack"}

        self.stacks["spack"] = Spack(self.prefix, scfgs.get("spack",{}), self._defaults)
        
    @property
    def spack(self):
        return self.stacks["spack"]

    @property
    def cfg(self):
        'Serialize to dict'
        return dict(defaults = self._defaults,
                    stacks = {n:s._cfg for n,s in self.stacks.items()})

    def dependency_graph(self, *seeds):
        '''
        Return dependency graph of stack names.

        Seeds may be stack objects or names
        '''
        gr = dict()
        for seed in seeds:
            if isinstance(seed, str):
                seed = self.stacks[seed]

            gr[seed.name] = set(list(getattr(seed,"deps",[])))
            gr |= self.dependency_graph(*gr[seed.name])
        return gr
            
    def dependency_list(self, *seeds, first=True):
        '''
        Return a flat, ordered list of stack names of the dependencies.
        '''
        gr = self.dependency_graph(*seeds)
        return list(graphlib.TopologicalSorter(gr).static_order())


    def save(self, output=None, overwrite=False):
        '''
        Save current state to our cfg_file unless output is given.

        If output is special "-", then write to stdout else output provides
        the name of file to which the state is written.
        '''
        text = yaml.dump(self.cfg, sort_keys=False)
        if output in ("-", "/dev/stdout"):
            print(text)
            return
        if not output:
            output = self._cfg_path
        else:
            output = Path(output)
        if output.exists() and not overwrite:
            raise click.UsageError(f'will not overwrite existing file: {output}.  Maybe try "-" as file name?')

        output.parent.mkdir(parents=True, exist_ok=True)
        output.write_text(text)
        debug(f'wrote {output}')

    def set_stack(self, name, **kwds):
        '''
        Define or update a stack of given name by patching kwds.

        Return object
        '''
        if name in self.stacks:
            stack = self.stacks[name]
            stack.merge(**kwds)
            return stack
        
        ret = self.stacks[name] = Stack(name, self.prefix, kwds, **self._defaults)
        return ret

        # scfg = self._cfg.get('stacks',{}).get(name, {})
        # self._cfg['stacks'][name] = merge_patch(dict(scfg), kwds)
        
    def assure_yaml(self, path, dat, force=False):
        path = Path(path)
        if path.exists() and not force:
            debug(f'not writing existing file: {path}')
            return
        path.parent.mkdir(parents=True, exist_ok=True)
        path.write_text(yaml.dump(dat, sort_keys=False))
        debug(f'wrote file: {path}')

    def paths(self, name):
        '''
        Return all canonical paths for stack.
        '''
        

        root = self.prefix / "spack" / name
        more = {k:root/k for k in "scope repo install environments".split()}
        more['git'] = root / "repo" / ".git"
        if name == "base":
            # Connect with Spack's structure that differs from how WCWC handles
            # others.  "repo" refers to Spack repo not git repo though these two
            # coincide for the "chained" repos.
            more['repo'] = more['repo'] / "var" / "spack" / "repos" / "builtin"
        return namedtuple("Paths", "root scope repo install environments git")(root=root, **more)



def setup_logging(log_output, log_level):
    try:
        level = int(log_level)      # try for number
    except ValueError:
        level = log_level.upper()   # else assume label
    log.setLevel(level)

    if not log_output:
        log_output = ["stderr"]
    for one in log_output:
        if one in ("stdout", "stderr"):
            sh = logging.StreamHandler(getattr(sys, one))
            sh.setLevel(level)
            log.addHandler(sh)
            continue
        fh = logging.FileHandler(one)
        fh.setLevel(level)
        log.addHandler(fh)

    debug(f'logging to {log_output} at level {log_level}')

def boolish(string, true, false, **kwds):
    if not string:
        return false
    string = string.lower()
    if string in "false no off disable disabled none".split():
        return true
    if string in "true yes on enable enabled".split():
        return true
    return kwds.get(string, string)

def maybe_reexec(prefix, image, image_prefix):
    '''
    Munge argv and reexec inside podman image.

    If image does not exist it is created.

    Image must have "wcwc" as its ENTRYPOINT and is assumed to run as root.

    In-image prefix depends on the value of image_prefix.
    - looks false, no volume is mounted and no --prefix given
    - looks true, use default prefix
    - if "same" or "internal" use the same as outside the container
    - else use what it names
    '''
    iamge = boolish(image, wcwc_image, None)
    if image is None:
        return
    if Path("/run/.containerenv").exists() or 'container' in os.environ:
        debug(f'we already in a container, not starting {image}')
        return
        
    image_prefix = boolish(image_prefix, wcwc_prefix, None, same=prefix, internal=prefix)

    assure_podman_image(image)

    argv = list(sys.argv)
    to_strip="-p --prefix -I --image -P --image-prefix"
    doomed = list()
    for ind, arg in enumerate(argv):
        for one in to_strip:
            if arg == one:
                doomed += [ind, ind+1]
                continue
            if arg.startswith(f'{one}='):
                doomed.append(ind)
                continue
    doomed.sort()
    doomed.reverse()
    for ind in doomed:
        argv.pop(ind)
    argv.pop(0)                 # remove "wcwc"

    pmargs = ["podman","run"]
    if prefix and image_prefix:
        (Path(prefix) / '.spack').mkdir(parents=True, exist_ok=True)
        pmargs += ['-v',f'{prefix}:{image_prefix}',
                   '-v',f'{prefix}/.spack:/root/.spack']
    pmargs += ['-it', '--rm', image]
    pmargs.append(f'--image=false')
    if image_prefix:
        pmargs.append(f'--prefix={image_prefix}')
    pmargs += argv              # original, surviving args

    pmargs_str = ' '.join(pmargs)
    debug(f're-exec: {pmargs_str}')
    os.execvp("podman", pmargs)  # does not return


# CLICK command line user interface

cmddef = dict(context_settings = dict(auto_envvar_prefix='WCWC',
                                      help_option_names=['-h', '--help']))
@click.option("-c", "--config", default=None, type=str,
              help="Specify a config file")
@click.option("-p", "--prefix", default=wcwc_prefix, type=str,
              help=f"Specify WCWC Spack installation prefix (def={wcwc_prefix})")
@click.option("-P", "--image-prefix", default=wcwc_prefix, type=str,
              help=f"Specify WCWC Spack installation prefix inside container (def={wcwc_prefix})")
@click.option("-I", "--image", default=None, type=str,
              help=f'Name podman image, or a true-like term to enable default or false-like to disable (the default)')
@click.option("-l","--log-output", multiple=True,
              help="log to a file [default:stdout]")
@click.option("-L","--log-level", default="info",
              help="set logging level [default:info]")
@click.group("wcwc", **cmddef)
@click.pass_context
def cli(ctx, config, prefix, image_prefix, image, log_output, log_level):
    '''
    Operate on the WCWC software ecosystem.
    '''
    setup_logging(log_output, log_level)
    debug(f'{prefix=} {image=} {image_prefix=}')

    maybe_reexec(prefix, image, image_prefix)  # does not return if rexec.

    debug(f'base group {sys.argv=}, {ctx.info_name=} {ctx.command.name=} {ctx.invoked_subcommand=} {ctx.params=}')
    ctx.obj = WCWC(prefix, config)


### USER COMMANDS
# User commands are directly in the main group.  

def use_stacks(with_spack=True, required=False):
    '''The command uses one or more stacks'''
    def decorator(func):
        @click.option("-S", "--stacks", default=None, type=str,
                      help="Set stacks to use as comma separated list")
        @click.pass_context
        @functools.wraps(func)
        def wrapper(ctx, stacks, *args, **kwds):
            #debug(f'use_stacks: {stacks=} {args=} {kwds=}')
            if stacks is None:
                stacks = ()
            elif stacks in ("all","known"):
                stacks = list(ctx.obj.stacks.values())
                debug(f'use_stacks: {[s.name for s in stacks]}')
            else:
                stacks = [ctx.obj.stacks[s] for s in stacks.split(",")]
                debug(f'use_stacks: {[s.name for s in stacks]}')

            if required:
                for stack in stacks:
                    for kind in ("scope", "repo"):
                        path = stack.path(kind)
                        if path.exists():
                            continue
                        raise click.UsageError(f"required stack lacks: {path}.  Try 'wcwc init -n {stack.name}'?")

            kwds['stacks'] = stacks
            if not with_spack:
                return func(*args, **kwds)
            
            kwds['spack_exe'] = ctx.obj.spack.execfunc(
                stacks=stacks, capture_error=False,
                capture_output=False, check=False)
            return func(*args, **kwds)
        return wrapper
    return decorator


def set_a_stack(with_spack=True):
    '''The command deals with a stack allowing re definition'''
    def decorator(func):
        @click.option("--tag",default=None, type=str, 
                      help=f"override default git tag (tag/hash/branch)")
        # @click.option("--branch",default=None, type=str,
        #               help=f"override default branch")
        @click.option("--url",default=None, type=str,
                      help=f"override default git url")
        @click.option("--remote",default="origin",
                      help=f"override the git remote name")
        @click.option("--source-path",default=None, type=str,
                      help=f"override source path to stack source")
        @click.option("--repo-path",default=None, type=str,
                      help=f"override source path to stack source")
        @click.option("--depends",default=None, type=str,
                      help=f"override dependency stacks (comma separated list)")
        @click.argument("name")
        @click.pass_context
        @functools.wraps(func)
        def wrapper(ctx, name, tag, url, remote, source_path, repo_path, depends, *args, **kwds):
            stack = ctx.obj.set_stack(name)
            kwds['stack'] = stack


            if tag:
                stack.set("tag", tag)
            # if branch:
            #     stack.set("branch", branch)
            if url:
                stack.set("url", url)
            if remote:
                stack.set("remote", remote)
            if source_path:
                stack.set("source_path", source_path)
            if repo_path:
                stack.set("repo_path", repo_path)
            if depends:
                stack.set("depends", depends)

            if with_spack:
                spack_exe = ctx.obj.spack.execfunc(
                    stacks=[stack], capture_error=False,
                    capture_output=False, check=False)
                kwds['spack_exe'] = spack_exe

            return func(*args, **kwds)
        return wrapper
    return decorator




def make_env(ctx, stacks, target, environment, specs):
    '''
    Common body function for user and admin env command.
    '''

    # Bring symmetry to the shared vs personal dichotomy.
    if stacks:
        stacks = stacks.split(",")
    else:
        stacks = []

    if target:                  # shared/system
        if not environment:
            raise click.UsageError("giving -T/--target requires also -e/--environment")
        if "/" in environment:
            raise click.UsageError("shared environment name can not look like a path")

        # Apparently, Spack places the named environment into the last scope.
        try:
            stacks.remove(target)
        except ValueError:
            pass
        stacks.append(target)

        target = ctx.obj.stacks[target]
        epath = target.path("environments") / environment
        ename = environment
        create_cmd = f'env create {ename}'
    else:                       # anonymous/personal
        if not environment:
            environment = "."
        epath = Path(environment).absolute()
        ename = str(epath)
        create_cmd = f'env create --dir {ename}'
        
    stacks = [ctx.obj.stacks[s] for s in stacks]
    spack_exe = ctx.obj.spack.execfunc(stacks=stacks, capture_output=True)

    if not epath.exists():
        spack_exe(create_cmd)

    # If personal env, make sure it has memory of the scopes that were used in making it.
    if not target:
        yaml_merge_patch(epath / "spack.yaml", {
            "spack": {
                "concretizer": {
                    "unify": "when_possible"
                },
                "repos": [s.path("repo",as_string=True) for s in stacks],
                "upstreams": {
                    "stacks": {
                        "install_tree": "/wcwc/opt"
                    }
                },
                "config": {
                    "source_cache": str(epath / "cache"),
                    "install_tree": {
                        "root": str(epath / "opt"),
                        "projections": {
                            "all": '{namespace}/{architecture}/{compiler.name}-{compiler.version}/{name}-{version}-{hash}'
                        }
                    }
                }
            }
        })

    for spec in specs:
        spack_exe(f'-e {ename} add {spec}')
    if specs:
        spack_exe(f'-e {ename} concretize') # --force

def user_spack(command):
    '''
    Wrap a spack command to make it a wcwc user command
    '''
    def decorator(func):
        @cli.command(command,
                     context_settings={
                         "ignore_unknown_options":True,
                         "help_option_names":[],
                     })
        @use_stacks(with_spack=True, required=True)
        @click.argument("spack_args", nargs=-1, type=click.UNPROCESSED)
        @functools.wraps(func)
        def wrapper(stacks, spack_exe, spack_args, *args, **kwds):
            cli = [command]+list(spack_args)
            #debug(f'spack wrapped: {cli=}')
            proc = spack_exe(cli)
            return func(proc)
        return wrapper
    return decorator

@user_spack("spec")
def spec(proc):
    '''
    Wrapper around spack spec.
    '''
    return proc.returncode

@user_spack("find")
def spack_find(proc):
    '''
    Find matching installed package instances.

    This wraps "spack find" and accepts -S/--stages <stages>
    '''
    return proc.returncode

@user_spack("list")
def spack_list(proc):
    '''
    List matching package names (not instances).

    This wraps "spack list" and accepts -S/--stages <stages>
    '''
    return proc.returncode



@cli.command("env")
@click.option("-S","--stacks", default=None, type=str,
              help="Comma-separated list of stack names which are upstreams to the environment")
@click.option("-T", "--target", default=None, type=str, 
              help="The name of the stack in which the environment is placed (for system environments)")
@click.option("-e", "--environment", default=None, type=str, 
              help="The directory for the environment")
@click.argument("specs", nargs=-1)
@click.pass_context
def cmd_env(ctx, stacks, target, environment, specs):
    '''
    Create a Spack Environment in a directory.

    The -S/--stacks gives a list of stacks providing packages (aka Spack
    "upstreams").

    An optional list of specs describing packages to add to the environment may
    be given.  These packages will be installed in a stack install tree if they
    are not yet existing.  Thus, if the user does not have write permission to
    the install area, this command will fail.

    The -T/--target indicates -e/--environment is a name for a system
    environment and not a directory for a user environment.

    This command is idempotent and may be repeated to add more specs.
    '''
    make_env(ctx, stacks, target, environment, specs)
    print(f'--> In WCWC, activate with: wcwc shell -e {environment}')

@cli.command("stacks")
@click.pass_context
def cmd_stacks(ctx):
    '''
    Show status about existence of known stacks.
    '''
    git = which("git")

    for stack in ctx.obj.stacks.values():
        path = stack.path("repo")
        if path.exists():
            ver = git(f'rev-parse --abbrev-ref HEAD', lines=1, cwd=str(path))
            info(f'{stack.name:20} {ver}')
        else:
            info(f'{stack.name:20} (missing: {path})')


@cli.command("envs")
@use_stacks(required=False, with_spack=False)
@click.pass_context
def cmd_user_envs(ctx, stacks):
    '''
    List the defined system/shared environments.
    '''
    stacks = [ctx.obj.stacks[sn] for sn in ctx.obj.dependency_list(*stacks)]
    for stack in stacks:
        if not stack.path("scope").exists():
            continue

        print(f'{stack.name}:')
        got = ctx.obj.spack.command("env list", stacks=[stack],
                                    capture_error=False, capture_output=False, check=False)
        if got.returncode:
            return got.returncode
        print()
        


@cli.command("scopes")
@click.pass_context
def cmd_scopes(ctx):
    '''List known scopes'''
    for name, dat in ctx.obj.cfg['repos'].items():
        paths = ctx.obj.paths(name)
        url=dat.get('url','')
        tag=dat.get('tag','')
        us=','.join(dat.get('upstreams',[]))
        exist = "installed" if paths.scope.exists() else "missing"
        info(f'{name:12} {paths.scope} ({exist}) {tag}')


@cli.command("show")
@click.option("-f","--format", default="yaml",
              help="format to output print")
@use_stacks(with_spack=False)
@click.pass_context
def cmd_show(ctx, format, stacks):
    '''
    Show information about a stack.
    '''
    for stack in stacks:
        if format == "yaml":
            info (yaml.dump(stack.cfg, sort_keys=False))
        else:
            info (str(stack.cfg))
    

def do_shell(ctx, stacks, shell, output, command, environment, load, keep):
    '''
    Body of shell command for user and admin.
    '''

    # figure out target shell
    if shell == "auto":
        shell = os.environ.get("SHELL",None)
        if not shell:
            user = os.environ.get("USER", run("id -u -n", lines=1))
            shell = run(f"getent passwd {user}", lines=1).split(":")[6]
        if not shell:
            raise ValueError("can not divine shell, give it explicitly")
    shell = shell.split("/")[-1].strip()

    ext = dict(sh="sh",bash="sh",dash="sh",zsh="sh",fish="fish",csh="csh",tcsh="csh")[shell]
    script = ctx.obj.spack.path("source")  / "share" / "spack" / f"setup-env.{ext}"
    script = str(script)

    spack_prefix = 'spack'
    if stacks:
        for stack in stacks.split(','):
            stack = ctx.obj.stacks[stack]
            path = stack.path('scope', as_string=True)
            spack_prefix += f' -C={path}'
            # note, need "-C=path" not "-C path" otherwise the "spack" shell
            # function does not think it is actually a shell function????

    # Command lines of shell environment settings
    settings = [ f'source {script}' ]
    if environment:
        settings += [f'{spack_prefix} env activate {environment}']

    for spec in load:
        settings += [f'{spack_prefix} load {spec}']
    
    if output:
        text = '\n'.join(settings)
        if output in ('-',"stdout"):
            print(text)
            return
        Path(output).write_text(text)
        return
        
    with tempfile.NamedTemporaryFile(delete=False) as rcfile:
        if keep:
            info(rcfile.name)
        else:
            settings += [f'rm -f {rcfile.name}']
        text = '\n'.join(settings)
        debug(f'Using configuration for {shell}:\n------------\n{text}\n------------')
        rcfile.write(text.encode())

    supported_shells = "bash, fish, tcsh"

    env = dict(os.environ)
    env["SHELL"] = shutil.which(shell)

    if command:
        if shell == "bash":
            command = f'source {rcfile.name} && {command}'
            os.execvpe("bash", ["bash", "-c", command], env)
        if shell == "fish":
            os.execvpe("fish", ["fish","-C", f"source {rcfile.name}", "-c", command], env)
        if shell == "tcsh":
            os.execvpe("tcsh", ["tcsh", '-c', command, "-b", rcfile.name], env)
        raise click.UsageError(f'command unsupported for shell: "{shell}", try one of: {supported_shells}')

    # subshell
    if shell == "bash":
        cmd=["bash","--rcfile", rcfile.name]
        debug(f'execute: {" ".join(cmd)}')
        os.execvpe("bash", cmd, env)  # does not return
    if shell == "fish":
        os.execvpe("fish", ["fish","-C", f"source {rcfile.name}"],env)
    if shell == "tcsh":
        os.execvpe("tcsh", ["tcsh","-i","-b", rcfile.name],env)

    raise click.UsageError(f'execute unsupported for shell: "{shell}", try one of: {supported_shells}')

@cli.command("shell")
@click.option("-S","--stacks", default=None, type=str, 
              help="Comma-separated list of stack names, if needed to resolve environment")
@click.option("-s", "--shell",
              default="auto",
              type=click.Choice(["sh","bash","dash","zsh","fish","csh","tcsh","auto"]),
              help="Set the shell flavor, default:auto")
@click.option("-o", "--output", default=None, type=str,
              help='Emit shell settings to given output, "-" or "stdout" for emitting to standard output')
@click.option("-c", "--command", type=str, default=None,
              help="Execute the command in a configured shell")
@click.option("-e", "--environment", default=None, type=str,
              help="Use given Spack Environment to determine shell settings")
@click.option("-l", "--load", type=str, default=[], multiple=True,
              help="Load the given package spec")
@click.option("-k", "--keep", is_flag=True, default=False,
              help="Retain settings file and emit its name (ignored for -o/--output)")
@click.pass_context
def cmd_user_shell(ctx, stacks, shell, output, command, environment, load, keep):
    '''
    Produce a configured shell environment.

    This is a user command.  WCWC admins should avoid using this to modify the WCWC
    installation.  Instead use command in the "wcwc admin" group.

    This command supports a "cross product" of behavior along these dimensions:

    - the shell flavor (fish, sh-like and csh-like)

    - the mode of supplying the target environment (settings, command or shell)

    - the make up of the target environment (base, load modules, activate environment)
    '''
    do_shell(ctx, stacks, shell, output, command, environment, load, keep)

@cli.command("version")
def cmd_version():
    'Print WCWC version'
    print(wcwc_version)


### ADMIN COMMANDS

@cli.group()
@click.pass_context
def admin(ctx):
    '''
    Commands intended for an WCWC administrator.
    '''
    debug(f'admin group {sys.argv=}, {ctx.info_name=} {ctx.command.name=}')
                



@admin.command("defaults")
@click.option("-f","--force-overwrite", is_flag=True, default=False,
              help="Allow to overwrite existing file")
@click.argument("output", nargs=-1)
@click.pass_context
def cmd_defaults(ctx, output, force_overwrite):
    '''
    Emit a default config file.

    By default, the config file is written under --prefix.
    An argument of "-" will write to stdout.
    Any other argument will be interpreted as a file name.
    '''
    if output:
        output = output[0]
    info(output)
    ctx.obj.save(output, overwrite=force_overwrite)

@admin.command("check-os")
def cmd_check_os():
    """Check if current running OS is supported"""
    got = run("lsb_release -ds", lines=1)
    if got in known_oses:
        return
    raise ValueError(f'not a supported OS: {got}')

@admin.command("oses")
def cmd_oses():
    '''
    Print names of supported operating systems, one per line.
    '''
    for one in known_oses:
        info(one)




# disable auto-help so we pass on "-h/--help" to spack.
@cli.command("spack")
@use_stacks()
@click.argument("args", nargs=-1, type=click.UNPROCESSED)
@click.pass_context
def spack(ctx, stacks, spack_exe, args):
    '''
    A wrapper around spack for WCWC admins.

    This adds some WCWC specific functionality including:
    - logging the command to the command DB
    - resolving a stack name to its scope

    WCWC admins should use this instead of bare "spack" for any tasks that
    involve modifying the Spack installation.

    Avoid using it to modify the WCWC area and instead use dedicated "wcwc
    admin" commands.

    This command is subject to podman image usage.
    '''
    got = spack_exe(args)
    return got.returncode


@admin.command("install")
@click.option("-S","--stack", default="spack", type=str, 
              help="The name of the stack in which to perform the installation")
@click.argument("specs", nargs=-1)
@click.pass_context
def install(ctx, stack, specs):
    '''
    Install a package in the context of a stack.

    This is a thin wrapper around "spack install" that makes sure to do the
    installation in the scope for a stack.

    This command is subject to podman image usage.
    '''
    if stack not in ctx.obj.stacks:
        raise click.UsageError(f'uknown stack: "{stack}"')

    got = ctx.obj.spack.command(["install"]+list(specs), stacks=[ctx.obj.stacks[stack]],
                                capture_error=False, capture_output=False)
    return got.returncode
    

@admin.command("init")
@click.option("--recurs", is_flag=True, default=True,
              help="recurs over upstreams, if any (default=False)")
@click.option("--force", is_flag=True, default=False,
              help="force overwriting (default=False)")
@set_a_stack(with_spack=False)
@click.pass_context
def cmd_admin_init(ctx, recurs, force, stack):
    '''
    Initialize support for the named stack.

    Spack itself is represented by the stack named "spack".

    If the stack name is not known in defaults or in the configuration file then
    it must be sufficiently described.

    If recurs is True (default), stacks on which the named stack depends will
    also be initialized.  Dependencies must be known.

    No actual Spack packages are installed.  See "wcwc install"

    This command is idempotent.

    This command is subject to podman image usage.
    '''
    debug(f"initialize stack: {stack.name}")
    stack.init(ctx.obj, recurs)
    

def assure_podman_image(name=wcwc_image, force=False):
    '''
    Assure named podman image exists.
    '''

    podman = which("podman", capture_error=False)

    if not force:
        got = podman(f'image exists {name}')
        if got.returncode == 0:
            log.debug(f'podman image for building exists as "{name}"') 
            return

    containerfile = '''
FROM debian:bookworm
RUN apt update \
    && \
    apt install -y \
      build-essential ca-certificates coreutils curl gfortran git gpg \
      lsb-release unzip zip \
      python-is-python3 python3 python3-distutils python3-venv python3-click python3-yaml \
    && \
    apt clean
COPY wcwc /usr/local/bin/
RUN useradd -ms /bin/bash wcwc && \
    mkdir -p /wcwc && \
    chown wcwc:wcwc /wcwc
ENV SPACK_USER_CONFIG_PATH /wcwc/.spack
# USER wcwc
# WORKDIR /wcwc
CMD ["bash"]
ENTRYPOINT ["wcwc"]
'''.encode()
    context = Path(__file__).parent.absolute()
    podman(f'build -t {name} -f - {context}', capture_output=False, input=containerfile)


def main():
    cli()

if '__main__' == __name__:
    # main()
    cli()

