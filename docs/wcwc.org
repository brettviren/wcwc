#+title: The Wire-Cell Workstation Cluster
#+setupfile: ~/org/setup.org
#+setupfile: ~/org/setup-topic.org
#+setupfile: ~/org/setup-readtheorg.org
#+options: toc:t

* meta :noexport:

#+begin_src elisp :results none
(setenv "PATH" (concat (getenv "PATH") ":" (expand-file-name "../scripts")))
#+end_src


* Introduction
:PROPERTIES:
:CUSTOM_ID: intro
:END:

This document describes the Wire-Cell workstation cluster (WCWC).  Sections [[#enroll]], [[#base]] and [[#stacks]] are intended to provide easy entry points to WCWC users (including using WCWC for software development). Section [[#spack]] gives a summary of information about Spack that is most salient to users of WCWC and developers of WCWC infrastructure.  Section [[#further]] provides guidance on optional ways to use WCWC.  The section [[#sysadmin]] describes use of Ansible and FreeIPA IDM to do OS-level sysadmin things for computers enrolled in a WCWC.  And finally the section [[#nabs]] gives details useful for implanting variants of WCWC.

This document, various tools and configuration are provided by the [[https://github.com/brettviren/wcwc][wcwc]] package.
It provides a program called ~wcwc~ that automates various user and administration tasks.  It including [[https://docs.ansible.com/][Ansible]] recipes for OS level administration (see section [[#ansible]]).  The recommended way to use tools from this package is with a direnv activated shell.  See [[#direnv]].

* Workstation enrollment
:PROPERTIES:
:CUSTOM_ID: enroll
:END:

As described here, WCWC instance resides on the BNL campus network.  It is comprised of a subset of the workstations used by the BNL Wire-Cell team.  To fully enroll a workstation into WCWC the owner must satisfy these requirements:

- Be a custodian or otherwise primary user of a workstation on the BNL campus network.
- Install a supported OS (currently Debian 12 / "bookworm").
- Request a static IP from BNL DNS admins and configure the OS to use it.
- Add the [[https://www.phy.bnl.gov/~bviren/wire-cell/docs/wcwc.pub][BNL WCWC admin SSH public]] keys to ~/root/.ssh/authorized_keys~.
- Convert the local user accounts so they have unique user IDs, change their files' permissions to match and to place their ~$HOME~ under a standard location (~/nfs/home/$USER~). 
- Notify the WCWC admin for further OS configuration and discuss any special needs.


The WCWC admin can help with these items is needed.  The WCWC admin will then install various OS packages and perform OS configuration and integration into the WCWC.  

#+begin_note
People are encouraged to make use of WCWC in other clusters and are free to apply their own structure.  A single user on a laptop can benefit from becoming its own WCWC.  Guidance on alternative WCWC structures is given in the section [[#further]]
#+end_note

The main features gained from the enrollment are:

- Access to ~/wcwc~ holding a large set of software builds of various stacks.
- Ability for the workstation owner to log into other WCWC workstations and have a shared ~$HOME~.
- Likewise, ability for other WCWC members to log into the workstation to make use of its resources.

* Base software stack
:PROPERTIES:
:CUSTOM_ID: base
:END:


With enrollment from section [[#enroll]] completed, we now provide a set of examples for how using the base software stack provided by WCWC.  Here, a "stack" refers to a particular set of packages.  A "package" refers to the abstract notion of some software project's body of work.  Each package in the stack may be installed to produce a package "instance" along with a concrete set of other packages instances that provide dependencies.  You may select among the instances for the purposes of running the software they provide or for developing against their libraries.

The WCWC software is built with the ~spack~ command from the [[https://spack.io/][Spack project]].  The ~spack~ command is exposed to the WCWC user and will be used in the examples without providing much explanation.  The user may read the excellent Spack documentation and refer to the [[file:wcwc-system.org][WCWC System]] document for additional details.

For new users, take note that the subsequent section [[#stacks]] repeats the examples from this section in forms modified to make use of "extended software stacks" that provide additional packages such as those relevant to Wire-Cell.

** Spack shell environment

The examples will rely on some initial shell environment configuring.
Discover and load a shell environment script appropriate for your shell:
#+begin_example
$ ls /wcwc/spack/base/repo/share/spack/setup-env.*

$ source /wcwc/spack/base/repo/share/spack/setup-env.sh
#+end_example

#+begin_note
Users who wish to may avoid such global shell environment manipulation.  See the document [[file:wcwc-alt.org]] for guidance on alternative methods.
#+end_note


** Ad-hoc use of individual packages
:PROPERTIES:
:CUSTOM_ID: spack-load
:END:



Next, discover available package *instances*.
#+begin_example
$ spack find
#+end_example
Finally, modify your shell environment to use a package instance and its dependencies.
#+begin_example
$ spack load root

$ root --version
ROOT Version: 6.30/06
#+end_example
To finalize the session you may exit the shell or unload any that were previously loaded
#+begin_example
$ spack unload root
#+end_example

When more than one instance of a package is installed, you may need to provide a more concrete [[https://spack.readthedocs.io/en/latest/basic_usage.html#sec-specs][spec]] than just a package name.  Here are some ways to better specify what to "load" after we discover available versions and variants of a package:
#+begin_example
$ spack find -lv root

$ spack load root@6.30.06

$ spack load root+minut

$ spack load root/arvd7i3
#+end_example


** Durable shell environment
:PROPERTIES:
:CUSTOM_ID: spack-env
:END:

A user can go far with just ~spack load~ but it becomes challenging to reproduce a particular shell environment as more packages and more specific packages are required.  To solve this, "Spack Environments" can be used.  For simple end-user, creating and using them can be done with:
#+begin_example
$ spack env activate --create --dir my-env
$ spack add root
$ spack concretize
#+end_example
This creates the directory ~my-env~ which will hold various items and acts as a [[https://spack.readthedocs.io/en/latest/configuration.html#configuration-scopes][Spack configuration scope]].
The *spec* given to ~spack add~ is equivalent to what you may given to ~spack load~.  Later in a fresh shell the shell environment configuration can be regained with:
#+begin_example
$ spack env activate my-env
#+end_example

#+begin_note
After initial creation, more packages can be subsequently added.  Run ~spack concretize~ after doing so.
#+end_note

To return your shell environment to the state before activating a Spack Environment, issue:
#+begin_example
$ spack env deactivate
#+end_example

You may ~rm~ a Spack Environment directory manually or have Spack do it:
#+begin_example
$ spack env remove my-env
#+end_example

** Developer environment
:PROPERTIES:
:CUSTOM_ID: spack-devenv
:END:

A Spack Environment, such as created in section [[#spack-env]] can be used to develop software in a simple way that is otherwise independent from Spack itself.  The exact steps depend on the software but in general:

1. Obtain the source tree (eg, via ~git clone~) for the package you will develop.
2. Configure its build system to search ~/path/to/my-env/.spack-env/view~ for dependencies.
3. Build your package as usual.

   See section [[#stack-dev]] for a concrete example.


** User-installation of Spack packages 

The Spack Environment created in section [[#spack-env]] *must* only ~spack add~ Spack package instances that have already been installed in the base Spack installation.  It is not possible for a user to ~spack install~ novel package instances into these limited Spack Environments.

However, such installation of Spack packages into the user Spack Environment can be supported after we modify the Spack Environment configuration file to point Spack at writable filesystem locations.
This can be done by editing the ~spack.yaml~ file in the environment directory but more easily it may be done using the provided ~wcwc~ command.
#+begin_example
wcwc devenv my-env
#+end_example
This command can be used to create the environment or to "upgrade" a previous environment to one from which packages may be installed.  Installation then performed like:
#+begin_example
spack env activate my-env
spack install --add <spec>
#+end_example
The ~--add~ will add the resulting package instance to the environment after installation.


** Spack develop support
:PROPERTIES:
:CUSTOM_ID: spack-develop
:END:

In section [[#spack-devenv]] we give basics for leveraging a Spack environment to develop some software in a manner that is otherwise not Spack-aware.
Spack also provides support for  [[https://spack-tutorial.readthedocs.io/en/latest/tutorial_developer_workflows.html#][developing software]] for which Spack does have a package recipe.
#+begin_example
$ spack add coreutils
$ spack concretize
$ spack develop coreutils@9.4
$ spack install
$ echo >> my-env/coreutils/src/false.c
$ spack install  # rebuilds
#+end_example

The ~spack install~ acts like a ~make install~ type step though it also includes configuring the local build system.  This makes it somewhat slow to use for extended development sessions.

We may clear out the development package:
#+begin_example
$ spack undevelop coreutils
#+end_example



* Extended software stacks
:PROPERTIES:
:CUSTOM_ID: stacks
:END:


So far, we have made use of the base Spack install.  WCWC provides support for extended software stacks that are on top of this base.  The list of supported stacks is evolving but current as of this writing the stack support status is as follows:

- base :: the stack provided by Spack itself.
- wirecell :: provides Wire-Cell Toolkit (supported) and Wire-Cell Prototype (tbd) through the [[https://github.com/wirecell/wire-cell-spack][wire-cell-spack]] repo.
- nusoft :: (tbd) [[https://github.com/NuSoftHEP/nusofthep-spack-recipes][nusoft recipes]] repo provides a base fo FNAL software used by neutrino experiments.
- art :: (tbd) the [[https://github.com/FNALssi/fnal_art.git][fnal art]] repo with support for /art/ and some other general packages including another packaging for Wire-Cell Toolkit
- larsoft :: (tbd) [[https://github.com/LArSoft/larsoft-spack-recipes][larsoft recipes]] for building LArSoft.
- dune :: (tbd) DUNE experiment software on top of /art/ and LArSoft
- dune :: (tbd) SBND experiment software on top of /art/ and LArSoft  

To use an extended software stack you must tell Spack to consider a corresponding Spack *scope*.  As mentioned in section [[#spack-env]], a scope is a directory holding Spack configuration files that augment configuration provided in other, more general scopes.  WCWC provides a scope for each stack in a predictable location:
#+begin_example
/wcwc/spack/<stack>/scope/
#+end_example
We can now repeat the previous examples using an extended stack.

** Using individual packages from a stack

In section [[#spack-load]] we used ~spack load~ to configure our shell environment to use a package from the base Spack.  For an extended stack, we repeat the same commands but tell Spack about the stack's scope.
#+begin_example
$ source /wcwc/spack/base/repo/share/spack/setup-env.sh
$ spack --config-scope=/wcwc/spack/wirecell/scope find wire-cell-toolkit
$ spack --config-scope=/wcwc/spack/wirecell/scope load wire-cell-toolkit
#+end_example

#+begin_note
Depending on your shell, it may be critical to use the ~=~ when giving the scope.  See [[https://github.com/spack/spack/issues/41936][Spack issue 41936]].
#+end_note

** Environments based on a stack
:PROPERTIES:
:CUSTOM_ID: stack-env
:END:


In section [[#spack-env]] we constructed Spack Environments that were built on the base Spack.  Here we repeat that example but build the environment on an extended stack.  In this context the stack's scope is called an /upstream/ and we need merely list them in the ~wcwc devenv~ command:
#+begin_example
wcwc devenv -U wirecell my-env
#+end_example
As before, this command can be run on an existing environment or to create a new one.  We may then activate the environment and ~add~ existing package instances from the extended stack or ~install~ them.
#+begin_example
$ spack env activate my-env
$ spack install --add wire-cell-toolkit

$ which wire-cell
/path/to/my-env/.spack-env/view/bin/wire-cell

$ wire-cell --help
...
#+end_example

** Develop on a stack
:PROPERTIES:
:CUSTOM_ID: stack-dev
:END:


In section [[#spack-devenv]] we outlined how to develop software by leveraging an installation in a Spack Environment's view tree.  Using the environment created on the ~wirecell~ stack in section [[#stack-env]] we give a concrete example of configuring the Wire-Cell Toolkit build to do just that:
#+begin_example
$ spack env activate my-env  # from before, and see note below

$ git clone git@github.com:wirecell/wire-cell-toolkit.git wct
$ cd wct/
$ ./wcb configure --prefix=/path/to/my-env/.spack-env/view/
$ ./wcb
#+end_example
This is a minimal example and more control is likely applied with the various ~--with-*~ options supported by ~wcb~.

#+begin_note
Some caution is needed with using an instance of the Spack installation of ~wire-cell-toolkit~ that includes dependencies on the ~root~ (ROOT) package.  This package includes defining the ~CC~ and ~CXX~ shell environment variables to the compilers provided by the versions of ~Clang~ internal to ROOT.  Besides causing the development build to use the wrong compilers, they do not behave correctly.  You *must* unset ~CC~ and ~CXX~ after the ~spack activate~. 
#+end_note

* Spack overview
:PROPERTIES:
:CUSTOM_ID: spack
:END:


Above we used the ~spack~ command as a catalyst for configuring our shell environment to use some installed software.  This command is part of the Spack software project which provides a broad set of features related to software management.  In addition to shell configuration,
Spack is a software "meta build" system.  It automates running the build systems of various software packages, honoring dependencies and organizing the products.  Spack can appear daunting to a new user but once a few of its concepts are understood it becomes approachable.  The concepts are often named and discussed with some ambiguity and so we provide a clear definition of the important ones here:

- package recipe :: A [[https://spack.readthedocs.io/en/latest/packaging_guide.html][recipe]] is a simple Python module found as ~<package>/package.py~ that provides instructions to Spack for how the native build system provided by the package source can be exercised.  Spack may then automatically apply the recipe, along with any build options and dependency constraints to produce a *package instance*.  Ambiguous with *instance*, it is not uncommon for a package recipe to be referred to simply as a "package".
- package instance :: The collection of files produced by a package installation residing under an *install tree* in an installation *prefix* sub-directory named with a pattern constructed from metadata known as a *projection*.  This allows multiple variant installations of the same package to coexist on disk.  Ambiguous with *recipe*, it is not uncommon for a package instance to be referred to simply as a "package".
- package repo :: A [[https://spack.readthedocs.io/en/latest/repositories.html][repo]] holds a collection of package recipes along with a ~repo.yaml~ configuration file.  It may be provided as a dedicated git repository.  Spack provides the ~builtins~ repo as part of its overall source tree that currently contains about 8,000 package recipes.  Smaller repos are distributed to build special-purpose portions of a software stack.  One example is [[https://github.com/wirecell/wire-cell-spack][wire-cell-spack]].
- spec :: A [[https://spack.readthedocs.io/en/latest/basic_usage.html#sec-specs][spec]] describes a *package instance* using a [[https://spack.readthedocs.io/en/latest/spack.html#module-spack.parser][small markup language]].  The simplest and most abstract spec is simply a package name.  To reduce ambiguity, more information can be added including the software version, build variant parameters, compiler and even the specs of dependencies.  From a potentially abstract spec and a set of package recipes, Spack can fully determine the spec including all dependencies in a process call *concretization*.
- scope :: A [[https://spack.readthedocs.io/en/latest/configuration.html#configuration-scopes][scope]] is directory with Spack configuration files.  Scopes follow an inheritance hierarchy.  This allows defining a scope to override some specific configuration as a particular task may require.  Common parameters that a scope may modify include the location of the install tree or other directories used by Spack or to redefine which repos that Spack should consider.
- view :: A [[https://spack.readthedocs.io/en/latest/packaging_guide.html#views][view]] is a directory tree with the usual ~{bin/,lib/,include/}~ etc sub-directories that one may expect under, /eg/ the ~/usr/local/~ prefix of Unix convention.  The contents of view represents the union of a number of package *instances* as viewed from their installation *prefix*.  The files from the selected instances are symlinked into the view tree.
- shell :: Spack has three closely related, easily confused but distinct concepts related to the user shell environment.  First, Spack can modify the user shell environment after the appropriate ~spack-env.*~ script is "sourced".  Then ~spack load <package>~ can apply a Spack [[https://spack.readthedocs.io/en/latest/command_index.html#spack-load][environment module]] further modify the shell environment to use the named package.  A more sophisticated version of this is a Spack [[https://spack.readthedocs.io/en/latest/environments.html][environment]] which combines a *view* and a *scope*.  When an environment is *activated* the user shell environment is modified to make use of the software in the view.  In both cases shell environment is modified to add to standard ~PATH~-like variables and any custom configuration specified in package recipes are applied.


With these basic concepts given, the remainder of this section provides guidance and examples for common tasks.


** Basics of running Spack

Spack is run from a command named ~spack~.  



** Spack shell environment
:PROPERTIES:
:CUSTOM_ID: spack-env
:END:

An end-user (not developer) may wish to use Spack Environment Modules to configure their shell environment to use some package.  This is a two step processes.

*** Internalize spack to your shell
:PROPERTIES:
:CUSTOM_ID: spackify
:END:


Find the Spack shell "setup" script matching your shell:
#+begin_example
ls /wcwc/spack/base/repo/share/spack/setup-env.*
#+end_example
Source the one that matches your shell.  The ~wcwc~ command can also help to discover the right script.
#+begin_example
wcwc spack-setup
source `wcwc spack-setup`
#+end_example
This causes the ~spack~ command to become a shell function.

To avoid mutating your current shell environment you may wish to start a new one:
#+begin_example
bash --rcfile `wcwc spack-setup -s bash`
#+end_example

*** Loading an environment module

After internalizing Spack environment as in section [[#spackify]] you may further modify your shell environment to make use of various software packages in a piecemeal manner using Spack's support for [[https://modules.readthedocs.io/][Environment Modules]].
#+begin_example
$ spack load root
$ root --version
ROOT Version: 6.30/06
Built for linuxx8664gcc on Jun 04 2024, 20:14:19
From heads/master@tags/v6-30-06
$ spack unload root
#+end_example

#+begin_note
When Spack provides more than one instance of a particular package you must uniquely qualify which to load by providing a more detailed Spack *spec* instead of just a simple package name.  

To discover all installed instances of a package and their qualifiers use, for example the command ~spack find root~.  See the Spack [[https://spack.readthedocs.io/en/latest/basic_usage.html#sec-specs][Basic Usage manual]] and Spack "spec" [[https://spack.readthedocs.io/en/latest/spack.html#module-spack.parser][reference docs]] for more info on how to provide a Spack *spec*.
#+end_note

** Spack Environments
:PROPERTIES:
:CUSTOM_ID: spack-envs
:END:

[[https://spack.readthedocs.io/en/latest/environments.html][Spack Environments]] provide a persistent and more sophisticated and powerful way to specify your shell environment configuration than do the similarly named Spack Environment Modules.  They come in two types:  "anonymous" (aka "personal") and "managed" (aka "shared").

- anonymous :: User is fully in control of the life cycle from creation to destruction.  User may add packages that have been installed by Spack


You the user are fully in control of the life cycle of a personal environment and you may install your own Spack packages in addition to adding 

 .  On the other hand, the Spack admin is in charge of the life cycle of managed environments so that users can benefit from sharing a common software stack and be freed from management duties.  A user should prefer using a managed environment unless there are none suitably defined.

The rest of this section describes how to create both types and how to exploit them for using and developing software.  The examples are kept brief by using the ~wcwc~ tool.  For understanding the details of what this tool is doing, see the [[file:wcwc-system.org]] document.

*** Environment creation

A user creates a personal environment and

*** Managed environments

Guidance for an admin to actually create a managed environment is in the [[file:wcwc-system.org]] document.  An end-user can list available managed environments:
#+begin_example

#+end_example


*** Personal environments
:PROPERTIES:
:CUSTOM_ID: personal-envs
:END:

You may create your own Spack Environments and you may use shared Spack Environments provided by your WCWC admin.

Here we will construct and activate a new Spack Environment that is *personal* (not shared).
#+begin_example
$ spack env activate --create --dir my-env
$ echo $SPACK_ENV
/home/bv/my-env
#+end_example

#+begin_note
The ~--dir~ indicates the directory to hold the environment bookkeeping files and it tells Spack that this is a personal environment.

As ~spack env activiate~ modifies your shell environment you must first follow the steps to internalize Spack environment as in section [[#spackify]].
#+end_note

It is now possible to add *previously installed* packages
#+begin_example
$ spack add root
$ spack concretize
$ which root
/home/bv/my-env/.spack-env/view/bin/root
#+end_example

Later, in a fresh shell, we may reactivate the environment by giving the environment directory that was previously created:
#+begin_example
$ spack env activate my-env
$ which root
/home/bv/my-env/.spack-env/view/bin/root
#+end_example


*** Environments and chaining for user installation
:PROPERTIES:
:CUSTOM_ID: user-install-area
:END:


Spack supports "chaining" Spack installations.  A user can employ this feature to install packages that do not exist in the main Spack installation area.  To enable this, modify the ~spack.yaml~ file created in the Spack Environment directory to add ~config~ and ~upstreams~ entry like:

#+begin_src yaml
spack:
  config:
    install_tree:
      root: /home/rootless/junk/my-env/install
    build_stage:
      - /home/rootless/junk/my-env/stage
    source_cache: /home/rootless/junk/my-env/cache
  upstreams:
    base:
      install_tree: /srv/bv/wcwc/spack/base/install
#+end_src
#+begin_note
You will see other entries in the environment's ~spack.yaml~ which were added by ~spack~.  In particular the ~specs~ list will be filled with any package specs named with ~spack add~
#+end_note

You can now install packages and add them to the environment.  For example:
#+begin_example
spack install --add jsonnet
#+end_example


*** Chaining for WCWC software stacks

The WCWC Spack packaging is composed of different Spack "repos".  Each provides packaging for a portion of an overall stack.  Each repo is configured to have its own installation area via a Spack /scope/.  If one repo depends on another it is chained via Spack /upstreams/ mechanism in order to satisfy dependencies.  We saw this same upstream chaining above when configuring the environment with its own ~install_area~.  There, the upstreams consisted of just the "base" installation.

The environment can be constructed on a particular portion the software stack.  For example:
#+begin_example
spack env deactivate   # if needed to exit a prior environment
spack env activate --create --dir my-env-wct
#+end_example

In ~spack.yaml~ we must list the full upstream chain.
#+begin_src yaml
spack:
  upstreams:
    wirecell:
      install_tree: /wcwc/spack/wirecell/install
    base:
      install_tree: /wcwc/spack/base/install
  repos:
  - /wcwc/spack/wirecell/repo
#+end_src
We can then (fake) "install" and add packages provided by the upstream:
#+begin_example
spack install --add wire-cell-toolkit
#+end_example
To install novel package instance not provided by the upstreams, set the other ~config~ items as described in section [[#user-install-area]].


*** Shared environments
:PROPERTIES:
:CUSTOM_ID: shared-envs
:END:

The WCWC admin may define named environments that reside in the central Spack installation area and which may shared by many users.  You may list the names of the available shared environments:
#+begin_example
$ spack env list
==> 1 environments
    wct_0-28-0_glpk-hdf-root
#+end_example
You may activate a shared environment similar to a personal environment by giving its name instead of a directory:
#+begin_example
$ spack env activate wct_0-28-0_glpk-hdf-root
$ echo $SPACK_ENV
/wcwc/spack/local/var/spack/environments/wct_0-28-0_glpk-hdf-root
$ which root
/wcwc/spack/local/var/spack/environments/wct_0-28-0_glpk-hdf-root/.spack-env/view/bin/root
#+end_example

#+begin_note
Shared environments can be useful for end users but their *view* directory is not writable.  A user can not modify shared environments.
#+end_note

* Going further
:PROPERTIES:
:CUSTOM_ID: further
:END:

A Spack Environment can be used to provide a basis for software development as its *view* directory, ie  ~$SPACK_ENV/.spack-env/view~, acts similarly to the traditional Unix ~/usr~ or ~/usr/local~ prefix.  To build a software package under development you may provide this prefix or in many cases rely on packages to be found via ~PKG_CONFIG_PATH~ and ~CMAKE_PREFIX_PATH~ that are set by the Spack Environment activation. 

** Spack views
:PROPERTIES:
:CUSTOM_ID: view
:END:

The kernel of a Spack Environment is a Spack View.  A view aggregates package instances via the file system to that they appear to be installed in a single ~/usr/local~-style tree.  Some reasons you may prefer a View over an Environment is for their simplicity, to put more control (and responsibility) into your hands or to avoid global modification to your shell environment.  Using a Spack View is also limiting.  While you will be able to "add" existing package instances to a view (and that's about all you can do) you will not be able to ~spack install~ novel packages into the view.  A *view* also has no Spack *scope* and so no way to override ~spack~ configuration. Of course, you can create your own scope but that step quickly takes you back to the pattern followed by Spack Environment and you are likely best off using that.

No spack shell environment modifications are required to create and use views but you will need to run the ~spack~ program directly.  You make a view by adding package instances:

#+begin_example
$ /wcwc/spack/base/repo/bin/spack \
  --config-scope=/wcwc/spack/wirecell/scope \
  view add -i my-view wire-cell-toolkit

$ ls -l my-view/bin/wire-cell 
lrwxrwxrwx 1 bv bv 141 Jul 10 15:22 my-view/bin/wire-cell -> /wcwc/spack/wirecell/install/linux-debian12-haswell/gcc-12.2.0/wire-cell-toolkit-0.28.0-rpjtpyms7morqmfi5zym5l7ftbwsnn7q/bin/wire-cell
#+end_example

View has one more trick.  If your desire is to use the view tree as a basis for development of a particular package, and Spack knows how to build that package, you may wish to provide all dependencies for that package but exclude the package itself.  This can be done like:

#+begin_example
$ rm -rf my-view

$ /wcwc/spack/base/repo/bin/spack \
  --config-scope=/wcwc/spack/wirecell/scope \
  view -e wire-cell-toolkit add -i my-view wire-cell-toolkit

$ ls -l my-view/bin/wire-cell
ls: cannot access 'my-view/bin/wire-cell': No such file or directory

$ ls -l my-view/lib/libspdlog.so
lrwxrwxrwx 1 bv bv 129 Jul 10 15:24 my-view/lib/libspdlog.so -> /wcwc/spack/base/install/linux-debian12-haswell/gcc-12.2.0/spdlog-1.13.0-ja5i24ki6bu4lq3c262jjqpqvwrlr47q/lib/libspdlog.so
#+end_example

** Using ~direnv~
:PROPERTIES:
:CUSTOM_ID: direnv
:END:

The [[https://direnv.net/][direnv]] program provides features similar to a Spack Environment.  See its very excellent documentation to learn how to configure your shell to utilize it.

*** Use the ~wcwc~ package with direnv
:PROPERTIES:
:CUSTOM_ID: direnv-wcwc
:END:

The ~wcwc~ package provides the ~wcwc~ command and Ansible recipes.  Both rely on OS level packages.  Additional environment setting is provided to direnv-enabled shells with the included ~wcwc/.envrc~ file.

 is from a direnv shell.  Initial installation is as follows:
#+begin_example
git clone git@github.com:brettviren/wcwc.git
cd wcwc
direnv allow

wcwc --help
#+end_example
Subsequent use requires merely
#+begin_example
cd wcwc
#+end_example


*** Develop with direnv
:PROPERTIES:
:CUSTOM_ID: direnv-dev
:END:

Direnv can be used to provide functionality similar to a Spack Environment and can even exploit the existence of one.  However, it offers alternative behavior in how shell environment is configured.  Instead of issuing explicit ~spack env activate~ and ~spack env deactivate~ commands, use of ~direnv~ allows the user to simply ~cd~ into a direnv-controlled directory tree.  Once the user changes out of this tree the configuration settings are automatically undone.

A view tree, be it bare as in section [[#view]] or part of a Spack Environment, can be easily used from a direnv ~.envrc~ file.  This is particularly useful pattern it to place a view one level under where ~.envrc~ resides:
#+begin_example
$ /wcwc/spack/base/repo/bin/spack \
  --config-scope=/wcwc/spack/wirecell/scope \
  view -e wire-cell-toolki add -i my-work/view wire-cell-toolkit

$ git clone git@github.com:wirecell/wire-cell-toolkit.git my-work/toolkit
$ git clone git@github.com:wirecell/wire-cell-python.git  my-work/python

$ cat << EOF > my-work/.envrc
layout python
load_prefix \$PWD/view
# load_prefix misses this?
PKG_CONFIG_PATH="\$PKG_CONFIG_PATH:\$PWD/view/share/pkgconfig"
EOF

$ cd my-work
$ direnv allow

$ cd python
$ pip install -e .
$ cd ..

$ cd toolkit
$ ./wcb configure --prefix=$DIRENV_DIR/view
$ ./wcb
$ ./wcb install
#+end_example
Likely you will wish to further control ~wcb~ with some number of ~--with-*~ flags.  This uses a trick to install the build products right into the view.  This makes a view a mix of symlinks and real files, but it works just fine.  You may elide the ~wcb install~ and run the build products in-place by adding some more lines to ~.envrc~ like:

#+begin_example
export BATS_LIB_PATH=$PWD/toolkit/test
PATH_add $PWD/toolkit/test/bats/bin
PATH_add $PWD/toolkit/build/apps
path_add LD_LIBRARY_PATH $PWD/toolkit/build/{apps,aux,cuda,gen,iface,img,pgraph,sig,sigproc,sio,tbb,util,root,clus}
#+end_example

Revisiting this project in the future requires simply:
#+begin_example
$ cd my-work
#+end_example
See the direnv documentation for all the useful tricks you can do in an ~.envrc~ file.  


* Administration
:PROPERTIES:
:CUSTOM_ID: sysadmin
:END:

This section describes the steps to integrate a workstation into WCWC, repeating some from [[#enroll]].

** Supported operating system

A WCWC workstation must run a supported operating system in order to reduce the variety that the WCWC admin must cope with.   The single choice currently is Debian "stable".  This was chosen for several reasons:

- Debian gives reasonably long life for each release.
- Eventual upgrades can be done in-place.
- Debian is well suited for scientific workstations due to its huge wealth of packages including those specific to scientific application (unlike eg RHEL based systems).

The workstation owner is encouraged to install the Debian "stable" distribution on their own.  However, the WCWC admin can provide assistance.

** Canonical primary user information

To reduce some technical complexities, a WCWC user is required to have a unique user identifier (UID) that is used across all workstations in the WCWC.  If the user has (or had) a BNL "life" number, it should be used as the UID.  If a user has only a BNL guest ID then a UID is constructed from the guest ID.  These are of the form a letter followed by four numbers: LNNNN.  A UID should be formed as: [L - "A" + 1]0NNNN.  

If the OS is newly installed, this UID convention can be followed when creating the account for the primary user.  In most cases, a potential WCWC workstation will already has a primary user with a nominal UID (usually 1000 or 1001).  To convert to the new user and group IDs run the following as root:

#+begin_example
  groupmod -g NEWGID GROUPNAME  
  usermod  -g NEWGID -u NEWUID USERNAME
#+end_example
The ~usermod~ command will change permissions in the user's ~$HOME~ but not elsewhere.  To list top-level directories owned by the old user ID run:

#+begin_example
  find / -type d -user OLDUID -prune 2>/dev/null
#+end_example
One may then change ownership for each directory listed.
#+begin_example
  chown --from=CURRENT_OWNER:CURRENT_GROUP -R NEW_OWNER:NEW_GROUP DIRECTORY
#+end_example

This must be performed for the primary user and any other local users that will be members of WCWC.  By "local user" we mean the user local to the workstation that physically provides that user's ~$HOME~.

** Enrollment into Physics IDM

The BNL physics department maintains an identity management system (IDM) based on FreeIPA.  It is used in the BNL WCWC to manage user accounts and NFS automounting.  The enrollment is partly manual and partly automated.

*** Basic enrolement
:PROPERTIES:
:CUSTOM_ID: basic-idm-enroll
:END:

#+begin_example
  # apt install freeipa-client
  # hostname
  # ipa-client-install \
    --server=idm3.phy.bnl.gov \
    --server=idm2.phy.bnl.gov \
    --server=idm1.phy.bnl.gov \
    --server=idm.phy.bnl.gov \
    --domain=phy.bnl.gov
  # ipa-client-automount --server=idm.phy.bnl.gov --location=wcwc-u
#+end_example
Make sure ~hostname~ returns a FQDN.  If not, set it with ~hostname~ and update ~/etc/hostname~ for after later reboots.  This requires the user/pass of a FreeIPA account that is authorized to enroll computers.

The workstation host and all its local users then requires some settings in FreeIPA:

*** Add the host

1. ~Identity~ -> ~Hosts~ -> ~hostname.phy.bnl.gov~.
2. Add primary owner's real name and other general info about the workstation in description and SAVE.
3. In the ~Host Groups~ tab, ~+Add~, add the host to the group ~wcwc-workstations~.

*** Add primary user

A local user of the workstation will already have a Physics IDM account if they have a Physics SSH gateway account.   If they do not have an account they must request one from: https://www.phy.bnl.gov/Accounts/.

#+begin_note
The local and IDM user names must match.  If a mismatch occurs, either a new local or a new IDM account is needed or one of them must be renamed.
#+end_note

Given the ~username~ in FreeIPA:

1. ~Identity~ -> ~Users~ -> ~username~
2. ~User Groups~, ~+Add~ and add to ~wcwc~.
   
The ~$HOME~ provided by the workstation for a local user which is NFS-mounted to other WCWC workstations.  A map the combines ~workstation~ and ~username~ information is updated with:

1. ~Network services~ -> ~Automount~ -> ~wcwc-u~ -> ~auto.u~ -> ~+Add~
2. The ~Key~ is the username
3. the ~Mount information~ is as follows, replacing ~WORKSTATION~ with the fully-qualified name of the workstation

#+begin_example
-fstype=nfs4 -sync,rw,soft,sec=sys,proto=tcp,port=2049 WORKSTATION:/home/&
#+end_example

Internally, FreeIPA assigns large user (and group) ID numbers while we wish to keep the BNL "life" number used at the OS level.  To allow this an "ID View" is needed for each user:

1. ~Identity~ -> ~ID Views~ -> ~wcwc~ -> ~+Add~ 
2. Fill in the user name and matching user login, desired UID matching GID, shell and home directory (~/home/USER~).
3. SAVE

*** One time setup

The above assumes the following setup has been done.  First, the ~wcwc~ user group

1. ~Identity~ -> ~Groups~ -> ~User Groups~ and make ~wcwc~
2. Add any initially known users.

The ~wcwc-workstations~ host group:

1. ~Identity~ -> ~Groups~ -> ~Host Groups~ and make  ~wcwc-workstations~
2. Add any initially known hosts

Host-based access control (HBAC) brings users to hosts and ~wcwcws~ is the name:

1. ~Policy~ -> ~HBAC~ -> ~+Add~ and make ~wcwcws~
2. Visit ~wcwcws~,
   - add the ~wcwc~ User Group,
   - add the ~wcwc-workstations~ Host Group
   - add HBAC services: (gdm, login and ssh).

Automounting is handled as a network service "location"

1. ~Network services~ -> ~Automount~ -> ~+Add~ and make ~wcwc-u~
2. Visit ~wcwc-u~ and  ~+Add~ an ~auto.u~
3. Click ~auto.master~ and +Add key with ~/u~ and ~auto.u~.
See above for entries that go in ~auto.u~.

ID views allow remapping UID and other things.
1. ~Identity~ -> ~ID Views~ -> ~+Add~ and make ~wcwc~
Add ID View entries as described above.


** Ansible setup
:PROPERTIES:
:CUSTOM_ID: ansible
:END:

See [[https://docs.ansible.com/][Ansible docs]] for details on Ansible.  Here we give the highlights.  We refer to ~admin~ as a user on an Ansible [[https://docs.ansible.com/ansible/latest/getting_started/][control node]].  It is ~admin~ that runs Ansible commands and must be able to login as user ~root~ to every target machine via keys.

*** Inventory

Add hosts to ~wcwc/ansible/inventory.yml~
#+begin_example
workstations:
  hosts:
    hierocles.phy.bnl.gov:
    heracles.phy.bnl.gov:
    aswork.phy.bnl.gov:
    # ....
#+end_example
The host name should be given fully qualified.

Then check inventory and connectivity:
#+begin_example
ansible-inventory --list
ansible-inventory --host hierocles.bnl
ansible workstations -m ping -l hierocles.phy.bnl.gov
#+end_example
All commands should succeed.

*** Running a play

An ansible "playbook" applies OS configurations.  If meek, one may limit the play to a newly added workstation with ~-l hostname~.  The main play for workstations can be run as:
#+begin_example
  $ cd wcwc/
  $ ansible-playbook -l 'heracles.phy.bnl.gov' ansible/playbooks/wcwc-workstation.yml 
#+end_example




* Nuts and bolts
:PROPERTIES:
:CUSTOM_ID: nabs
:END:

This section is not intended for "normal" users but expert users, WCWC administrators or just anyone that wants to understand how WCWC works in more detail.

** Ways to get the software

This section gives details on how workstations may be configured to get the ~/wcwc~ software area.

*** NFS client
:PROPERTIES:
:CUSTOM_ID: nfs-client
:END:

Most WCWC workstations will access the WCWC software under ~/wcwc~ via an NFS-mount.  This requires the workstation to share connectivity with an NFS-server providing this volume.  Typically this means the two computers must share a common LAN.

To configure a workstation as an NFS client for the BNL WCWC run this as root:
#+begin_example
cat << EOF >> /etc/fstab
lycastus.phy.bnl.gov:/wcwc /wcwc nfs4 _netdev,auto  0  0
EOF

mount /wcwc
#+end_example
The ~lycastus~ host is relevant only on the BNL campus network.


*** Copy client
:PROPERTIES:
:CUSTOM_ID: copy-client
:END:

A workstation can instead provide ~/wcwc~ by periodically synchronizing its files from some other workstation that has it as an NFS-mount.  This can be preferred for home workstation or laptop use.

A copy of ~/wcwc~ is fully "owned" by the user in this case and the user is free to use it as they wish.  However, it is recommended that the user *not* copy ~/wcwc~ so that it is owned by the normal user.  Instead, the ~/wcwc~ area should be managed by a special user.  This is to assure normal users can not write to the area and cause chaos.  As user ~root~, create the special user ~wcwc~ and make ~/wcwc~ with proper ownership:
#+begin_example
useradd -c 'Wire-Cell Workstation Cluster User' -d /home/wcwc -m -s /bin/bash wcwc
mkdir /wcwc
chown wcwc:wcwc /wcwc
#+end_example
You are free to copy files how you wish.  Use of ~rsync~ over ~ssh~ is recommended.  Configure the ~wcwc~ user's SSH config file like:
#+begin_example
mkdir .ssh
chmod 700 .ssh
cat << EOF >> ~/.ssh/config
Host hierocles.bnl
        ControlMaster auto
        ControlPath ~/.ssh/socket-%r@%h:%p
        ControlPersist 10m
        ForwardAgent yes
        ForwardX11 yes
        HostKeyAlias hierocles
        Hostname hierocles
        PreferredAuthentications publickey
        ProxyCommand ssh -A bviren@gateway.phy.bnl.gov -W %h:%p
        ServerAliveInterval 60
        User bviren
EOF

ssh hierocles.bnl
#+end_example

#+begin_note
The example assumes a real BNL user (~bviren~) can SSH to a the ~wcwc~ account, forwarding an SSH key that allows access to a WCWC workstation (~hierocles~) via a BNL SSH gateway and that provides the ~/wcwc~ upstream mount.
#+end_note

Periodically run this ~rsync~ command to synchronize:
#+begin_example
$ rsync --del --archive hierocles.bnl:/wcwc/ /wcwc/
#+end_example

#+begin_note
Including the trailing ~/~ in the source part is important.  The ~--del~ will cause the absence of any files in the source to be reflected in the destination.
#+end_note

*** Building from scratch
:PROPERTIES:
:CUSTOM_ID: build-it
:END:

The ~/wcwc~ directory, or indeed any location, can be populated from a green field replicating the steps used to produce the ~/wcwc~ directory on a "real" WCWC NFS server.  Start with a supported OS, install some packages and create a dedicated ~wcwc~ user:

#+begin_example
$ apt install build-essential ca-certificates coreutils curl environment-modules \
  gfortran git gpg lsb-release python3 python3-distutils python3-venv unzip zip

$ useradd -c 'Wire-Cell Workstation Cluster User' -d /home/wcwc -m -s /bin/bash wcwc
$ mkdir /wcwc
#+end_example

The heavy lifting is done by the ~wcwc~ program.  The base Spack can be installed with
#+begin_example
$ wcwc install-stack
#+end_example
This will install into ~/wcwc~.   An alternative location can be given
#+begin_example
$ wcwc --prefix /srv/wcwc install-stack
#+end_example
Or, the ~WCWC_PREFIX~ shell environment variable may be set.

By default the ~wcwc install-stack~ command will install the base Spack support.  To install other stacks, simply name them.
#+begin_example
$ wcwc install-stack wirecell
#+end_example
The known stacks name "upstream" stacks on which they depend.  This dependency tree can be walked to recursively install the target stack and any dependencies.
#+begin_example
$ wcwc install-stack -r wirecell 
#+end_example
If a stack is unknown to ~wcwc~ it can be specified.  See ~wcwc install-stack --help~.

The result will be WCWC software area but currently with no actual packages installed.

** Ways to provide the software

*** NFS Server
:PROPERTIES:
:CUSTOM_ID: nfs-server
:END:

The primary distribution mechanism for the ~/wcwc~ area is simple NFS.  
The following is needed to configure a WCWC workstation with this role:
#+begin_example
apt install nfs-kernel-server 

useradd -c 'Wire-Cell Workstation Cluster User' -d /home/wcwc -m -s /bin/bash wcwc
mkdir -p /nfs/ro/wcwc

cat << EOF >> /etc/fstab
/data1/wcwc /wcwc        none bind,uid=1001
/data1/wcwc /nfs/ro/wcwc none bind,uid=1001
EOF

# one time
mount /wcwc
mount /nfs/ro/wcwc

cat << EOF >> /etc/exports
/nfs		130.199.22.0/23(ro,sync,crossmnt,no_subtree_check,fsid=0)
/nfs/ro/wcwc	130.199.22.0/23(ro,sync,no_subtree_check)
EOF

exportfs -a
showmount -e
#+end_example

The bind mount on ~/nfs~ are to satisfy certain NFS requirements and on ~/wcwc~ to provide a the canonical location when the root file system is too small to host software build products.   The IP addresses are examples relevant to the BNL campus network.

Once a ~/wcwc~ is available, see section [[#build-it]] to intialize it with Spack stacks and section [[#installing-packages]] for populate ~/wcwc~ with package instances.

*** Installing packages
:PROPERTIES:
:CUSTOM_ID: installing-packages
:END:

The WCWC Spack area is a little non-standard in that it is partitioned into "stacks".  Each stack exists under

#+begin_example
/wcwc/spack/<stack>/{environments,install,repo,scope}/
#+end_example

The ~base~ stack is Spack itself.  It's source resides under ~base/repo/~ and thus its actual Spack package repository is deeper under ~base/repo/var/spack/repos/builtin~.  The other stacks have their Spack package repository directly under ~<stack>/repo/~.

When installing packages, the WCWC admin must take care to do so "in" the ~<stack>/scope/~ that provides the Spack package that is being installed.

It is possible to install packages directly with the ~spack~ command but doing installations through ~wcwc~ can help to avoid shell environment configuration, more easily refer to a scope and support non-standard ~/wcwc~ locations.  To deal with non-standard locations:
#+begin_example
$ export WCWC_PREFIX=/path/to/nonstandard/wcwc  # not needed if using /wcwc
$ alias wcwc /path/to/wcwc/scripts/wcwc         # or add to your PATH
#+end_example

To install to base stack.
#+begin_example
wcwc spack install zlib
#+end_example
To install to extended stack
#+begin_example
$ wcwc spack install --stack wirecell wire-cell-toolkit
#+end_example

*** Defining managed environments
:PROPERTIES:
:CUSTOM_ID: managed-env
:END:


TBD.

