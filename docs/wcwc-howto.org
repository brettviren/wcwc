#+title: How to do various things on WCWC.
#+setupfile: wcwc-setup.org

This document collects various recipes to perform some specific tasks.  It assumes basic understanding of WCWC and the ~wcwc~ command (see [[file:wcwc.org]]) and in some cases assumes the BNL WCWC (see [[file:wcwc-bnl.org]]).  If there is something not here that you think would be useful to add, feel free to reach out to the WCWC admin or make an Issue or PR on the [[https://github.com/brettviren/wcwc][WCWC GitHub]].  

* meta :noexport:

#+begin_src elisp :results none
(setenv "PATH" (concat (getenv "PATH") ":" (expand-file-name "../scripts")))
#+end_src

#+begin_src sh :results output drawer
scp wcwc-howto.html hierocles.phy.bnl.gov:public_html/wire-cell/docs/
#+end_src

#+RESULTS:
:results:
:end:

* Listing packages inside a Spack Environment
:PROPERTIES:
:CUSTOM_ID: find-in-env
:END:


When a Spack Environment is "activated", Spack sees only the subset of packages
that have been added to the environment when it was constructed.  Thus the usual ~find~ command may be used.

#+begin_example
$ wcwc shell -e <env-name-or-dir>
$ wcwc find
#+end_example

* Use PyTorch

This section describes some ways to use PyTorch.
See also [[file:wcwc-packages.org::#torch]] and [[file:wcwc-packages.org::#cuda]].

** The ~py-torch~ spec

In particular ~py-torch~ can require variants to be specified.  In particular with or without CUDA and in some cases the CUDA compute capability (aka CC aka ~cuda_arch~) must be included.  Some typical, though partially specified variants are:

- ~py-torch~cuda~ :: CPU-only build
- ~py-torch+cuda~ :: CPU+GPU build
- ~py-torch+cuda cuda_arch=89~ :: CPU+GPU specifying the nVidia compute capability (CC) version 

Not all CC versions may be available.  CC 8.9 (~89~) covers a large range of hardware (up to 40xx) and software versions (up to 11.x).  See [[file:wcwc-packages.org::#cuda]] for some details.

To see all package instances that are available (but note section [[#find-in-env]]).
#+begin_example
$ wcwc find -lv py-torch
#+end_example
#+begin_src sh :exports results :results output :wrap example
wcwc find -lv py-torch
#+end_src

#+RESULTS:
#+begin_example
-- linux-debian12-x86_64 / gcc@12.2.0 ---------------------------
2dj527f py-torch@2.4.0~caffe2+cuda+cudnn~custom-protobuf~debug+distributed+fbgemm+gloo+kineto~magma~metal+mkldnn+mpi~nccl+numa+numpy+onnx_ml+openmp+qnnpack~rocm+tensorpipe~test~ucc+valgrind+xnnpack build_system=python_pip cuda_arch=89
#+end_example
Specifying an exact instance with the hash may be a useful shorthand: ~py-torch/2dj527f~.


** Environment Module

To use an installed version of ~py-torch~ via an Environment Module:
#+begin_example
$ wcwc shell -l 'py-torch+cuda'
$ python -c 'import torch; print(torch.cuda.is_available())'
True
$ python -c 'import torch; print(torch.cuda.device_count())'
2
#+end_example

** Spack Environment

A Spack Environment with an added instance of ~py-torch~ can be made like:
#+begin_example
$ wcwc env -e py-torch-env "py-torch+cuda cuda_arch=89"
--> In WCWC, activate with: wcwc shell -e wcwc-env

$ wcwc shell -e wcwc-env
$ python -c 'import torch; print(torch.cuda.is_available())'
True
$ python -c 'import torch; print(torch.cuda.device_count())'
2
#+end_example


* Use Spack View to develop WCT
:PROPERTIES:
:CUSTOM_ID: spack-view-wct
:END:

** Quick start

To create a default developer area at ~<path>~ run:

#+begin_example
$ wcwc task wct-dev-view <path>
#+end_example

For options see:
#+begin_example
$ wcwc task wct-dev-view --help
#+end_example

Next, examine and possible modify the ~direnv~ configuration file
#+begin_example
$ emacs <path>/.envrc
#+end_example

When happy, enter the directory and enable the environment
#+begin_example
$ cd <path>/
$ direnv allow
#+end_example
Anytime later you may edit ~.envrc~ and ~direnv allow~ the changes.

The initial command will have printed initial guidance on building the development area which are illustrated here.  First, install the cloned ~wire-cell-python~:
#+begin_example
$ cd <path>/python
$ pip install -e .
#+end_example
This installs into a Python virtual environment that is automatically activated by ~direnv~.  You will typically not need to examine it but it resides under ~<path>/.direnv/~.

Next, configure ~wire-cell-toolkit~ to build:
#+begin_example
$ cd <path>/toolkit
$ ./wcb configure --prefix=$PREFIX --boost-mt --boost-libs=$PREFIX/lib --boost-include=$PREFIX/include --with-jsonnet-libs=gojsonnet
#+end_example
See ~./wcb --help~ for all the many ~--with-*~ options.  This minimal example will automatically locate many of the externals provided in the "view".

Finally, build:
#+begin_example
$ ./wcb
#+end_example
You may then run ~wire-cell~, other WCT application programs and the many WCT test programs as well as Wire-Cell Python programs:
#+begin_example
$ wire-cell --help

$ which wire-cell
<path>/toolkit/build/apps/wire-cell

$ ./build/util/wcdoctest-util

$ ./build/util/test_testing

$ wirecell-util --help
#+end_example

With the environment configured by ~<path>/.envrc~ you do not need to run ~./wcb install~.
But, if you do files are installed into the view tree.

The next section gives some explanation of what was just made and the remaining sections give details about this developer environment including how to create it by hand.

** Explanation

The developer area is based on a Spack "view" providing the required external packages.  A Spack view is a directory tree that represents the union of the directory tree of all the external packages.  This is simply a directory tree with all the package files symlinked.


A view happens to form the kernel of a Spack Environment but here we use it effectively by itself.
It is possible to use a Spack Environment to provide a developer area but using a view directly results in a simpler, more transparent result.

However, a view has no shell environment aspect and it is convenient to replace this aspect that otherwise a Spack Environment may supply with something.  Here, [[https://direnv.net][direnv]] fills that gap.  It allows the developer to directly and easily modify the environment simply editing the ~<path>/.envrc~ file which is similar, if not exactly like a shell "rc" aka "setup" script.  Note, never "source" a ~.envrc~ file but instead rely on ~direnv~ to apply it to your shell session.

In the above quick start, the initial ~.envrc~ file sets the various ~PATH~-like variables to directories in the "view" tree as well as directories under the WCT's ~<path>/toolkit/build/~ directory (to avoid needing ~./wcb install~).  In addition, a Python virtual environment is configured so that the ~pip install~ inside ~<path>/python/~ makes the ~wire-cell-python~ package available for use.

** Configure your shell for ~direnv~
:PROPERTIES:
:CUSTOM_ID: configure-direnv
:END:

On BNL WCWC this step is performed by the system for the user.  For other users or for more information about use of ~direnv~ in WCWC see [[file:wcwc-packages.org::#direnv]].

** Determine specs to seed the view
:PROPERTIES:
:CUSTOM_ID: view-seeds
:END:

A view must be created with one or more "seed" packages.  These are installed package instances (Spack specs).  By default, ~wct task wct-dev-view~ will select an installed ~wire-cell-toolkit~ as a single seed simply by picking the last one listed (specifically via ~spack find --json wire-cell-toolkit~).  One or more seeds can be given explicitly:
#+begin_example
$ wcwc find -lv wire-cell-toolkit

# Pick one and name it by its hash

$ wcwc task wct-dev-view --seed wire-cell-toolkit/q3zolqz
#+end_example

** Create the view
:PROPERTIES:
:CUSTOM_ID: create-view
:END:

The ~wcwc task wct-dev-view~ command does this for you but if you wish to build the view manually you may use the lower-level ~wcwc view~ command like:
#+begin_example
$ wcwc view -S STACK -e EXCLUDE -d TOPDIR -s SEED/HASH TOPDIR/VIEWDIR
#+end_example
For our specific example, the command is:
#+begin_example
$ wcwc view -S wirecell -e wire-cell-toolkit -d hio-fix -s wire-cell-toolkit/q3zolqz hio-fix/local
#+end_example
The explanation of the arguments:
- ~-S/--stacks~ names any WCWC software *stacks* providing required packages.  We name ~wirecell~ as that is what provides ~wire-cell-toolkit~.
- ~-e/--exclude~ we want to *exclude* installation of WCT itself as we will be later installing our own from source.  A simple package name (not a more full spec) must be provided.  Omit this option if you plan to merely use WCT instead of build a development version.  You may start out as a user and convert to a developer, see section [[#convert-user-to-dev]].
- ~-i/--ignore-conflicts~ will *skip* including files that are common to multiple packages.  This is required to ignore conflicts due to packages that pollute common paths, eg ~<view>/README~ files.
- ~-d/--direnv~ defines the top level of a directory tree to be controlled by *direnv*.
- ~./hio-fix/local~ defines the the *view* directory.
#+begin_note
Creating the view can take minute or so.  The worked example here results in over 100k symlinks created across more than 13k directories.
#+end_note

** View tree structure
:PROPERTIES:
:CUSTOM_ID: view-tree
:END:
In section [[#create-view]] we placed the view directory as a subdirectory of the one controlled by ~direnv~.  It produces an initial structure like:
#+begin_example
./hio-fix/.envrc    # the direnv configuration file 
./hio-fix/local/    # the Spack View directory tree
#+end_example
The name ~local/~ is chosen to be reminiscent of the traditional Unix prefix ~/usr/local~.  Like that, the view tree has the usual ~local/{bin,lib,include}~ areas.  This gives us "room" to add WCT and WC Python source in sibling directories (section [[#clone-source]]):
#+begin_example
./hio-fix/toolkit/  # wire-cell-toolkit source
./hio-fix/python/   # wire-cell-python source
#+end_example

** Use the view
:PROPERTIES:
:CUSTOM_ID: use-view
:END:

We can now enter any directory under the top-level one and our shell environment will be automatically set:
#+begin_example
$ cd hio-fix/  
# 1. Allow direnv to apply settings
$ direnv allow
# 2. Examine the direnv configuration file
$ cat .envrc
#+end_example
1. We must "allow" ~direnv~ at least once.  After being allowed, ~direnv~ will remember for the future.  
2. The ~.envrc~ file syntax is essentially that of ~bash~ with some additional commands defined by ~direnv~.  See the [[https://direnv.net/man/direnv-stdlib.1.html][direnv-stdlib(1)]] man page for a list of available commands.  
The shell settings will be automatically undone by ~direnv~ by simply changing directory to be outside this tree:
#+begin_example
$ cd 
#+end_example

** Destroy the view
:PROPERTIES:
:CUSTOM_ID: destroy-view
:END:

When the view is no longer required its directory may simple be removed:
#+begin_example
$ rm -rf hio-fix/local/
#+end_example

You may of course wish to remove the top level directory as well:
#+begin_example
$ rm -rf hio-fix/
#+end_example


** Get the source to develop
:PROPERTIES:
:CUSTOM_ID: clone-source
:END:
The ~wcwc task wct-dev-view~ command will automatically clone ~wire-cell-toolkit~ and ~wire-cell-python~.  By default it will check out the ~master~ branch of each.  The ~wire-cell-toolkit~ branch can be chosen at creation time:
#+begin_example
$ wcwc task wct-dev-view --ref apply-pointcloud
#+end_example
You can of course later use ~git switch~ etc to change your clone.

** Customize ~.envrc~ for WCT
:PROPERTIES:
:CUSTOM_ID: custom-envrc
:END:

If the low level ~wcwc view~ command is used, the ~.envrc~ is initialized with minimal configuration that can serve as a good but generic starting point.  The ~wcwc task wct-dev-view~ will provide a more full-featured configuration tailored to WCT development (as described above).

The developer is encouraged to edit ~<path>/.envrc~ as/if needed.  After a change to ~.envrc~, a ~direnv allow~ must be reissued.

** Install ~wire-cell-python~
:PROPERTIES:
:CUSTOM_ID: install-wcpython
:END:

Before installing the WCT package we will install the copy of ~wire-cell-python~ that was cloned in section [[#clone-source]].   This package is not strictly required in order to build or use WCT.  However, it provides various useful auxiliary commands and some WCT unit tests can make use of it.
#+begin_example
  $ cd python
  $ pip install -e "."
  $ cd ..
#+end_example
Here we use the standard Python tool ~pip~ to install the package.  Be sure to include the ~"."~ (quotes added for visibility) which tells ~pip~ to consider the package that is in the current working directory.  The ~-e~ is given to allow us to later edit the Python code and have our changes immediately available for running.  The package is installed into the Python virtual environment that ~direnv~ has created for us due to the ~layout python~ line in the ~.envrc~ file.  For this example, the location ~hio-fix/.direnv/python-X.Y.Z/~ is used.

** Configure WCT builder
:PROPERTIES:
:CUSTOM_ID: configure-wct-build
:END:
WCT is built with the provided ~./wcb~ (wire-cell builder) tool.  In WCT, this tool is simply a copy of the plain [[https://waf.io/][waf]] command which can also be used.  


#+begin_example
  $ cd toolkit
  $ ./wcb configure --prefix=$PREFIX \
       --with-cuda=no --with-libtorch=no --with-root=no \
       --boost-mt --boost-libs=$PREFIX/lib --boost-include=$PREFIX/include \
       --with-jsonnet-libs=gojsonnet
#+end_example
Some explanation:
- The ~./wcb --prefix=$PREFIX~ provides a hint to check the prefix for externals.
- The ~--with-*=no~ flags are used to avoid features not required in order reduce build time.
- Boost can not currently be auto-detected in ~$PREFIX~ so we must be explicit (see [[https://github.com/WireCell/wire-cell-toolkit/issues/334][#334]]).
- We say to use the faster Go Jsonnet library instead of the default C++ ~libjsonnet~.

To use Torch, one needs to add the variant ~+torch~ to the WCT Spack package and then to build WCT for development some special help to ~./wcb~ is needed as Spack's ~py-torch~ package installs Torch libraries in an unconventional location:
#+begin_example
$ ./wcb configure [...] \
        --with-libtorch=$PREFIX/lib/python3.11/site-packages/torch 
#+end_example
Similarly, to use CUDA one needs to add the variants ~+cuda~ one needs:
#+begin_example
$ ./wcb configure [...] \
        --with-cuda-lib=/usr/lib/x86_64-linux-gnu,$PREFIX/targets/x86_64-linux
#+end_example
These two variants may be combined (~+torch+cuda~) for Torch + CUDA and likewise the ~./wcb~ commands are composed:
#+begin_example
$ ./wcb configure [...] \
        --with-cuda-lib=/usr/lib/x86_64-linux-gnu,$PREFIX/targets/x86_64-linux
        --with-libtorch=$PREFIX/lib/python3.11/site-packages/torch 
#+end_example
Note the two library paths for CUDA are required as Spack's ~cuda~ package provides CUDA libraries *except* ~libcuda.so~.  The NVIDIA "driver" package provides ~libcuda.so~.  The example here is for Debian.


** Post-hoc exclusion of package files from a view
:PROPERTIES:
:CUSTOM_ID: convert-user-to-dev
:END:

When running the ~wcwc view~ command as above (or implicitly when using ~wcwc task wct-dev-view~) we used ~wire-cell-toolkit~ for the seed and we also excluded its files from the view with the ~-e/--exclude~ option.  This results in a view that contains all the dependencies for ~wire-cell-toolkit~ but not the files for ~wire-cell-toolkit~ itself.  It is useful to exclude ~wire-cell-toolkit~ files to avoid any confusion between the versions provided by the Spack package instance and the versions we wish to build from our cloned source.

When building the view by hand it is possible to forget to exclude the ~wire-cell-toolkit~ files.  If this happens the view can be removed and remade or simply ~rm~ the WCT files as:
#+begin_example
$ rm -rf hio-fix/local/bin/{wire-cell,wc*} \
         hio-fix/local/lib/libWireCell* \
         hio-fix/local/include/WireCell* 
#+end_example


* Add existing package to a Spack Environment

The ~env~ command can simply be rerun.

#+begin_example
$ wcwc env -e test-env
$ wcwc env -e test-env zstd
$ wcwc shell -e test-env "zstd --version"
#+end_example

* Install a novel package to a Spack Environment

t.b.d. (currently broken)
